[
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "Changelog",
    "section": "",
    "text": "All notable changes to this project will be documented in this file.\nThe format is based on Keep a Changelog, and this project adheres to Semantic Versioning. Dates formatted as YYYY-MM-DD as per ISO standard.\n\n\nSet up repository and defined scope of reproduction.\n\n\n\nCode from original study\nGreen open access version of study article from arXiv\nPlanned scope for reproduction\n\n\n\n\n\nModified template to be about Shoaib and Ramamohan 2022"
  },
  {
    "objectID": "CHANGELOG.html#v0.1.0---2024-06-21",
    "href": "CHANGELOG.html#v0.1.0---2024-06-21",
    "title": "Changelog",
    "section": "",
    "text": "Set up repository and defined scope of reproduction.\n\n\n\nCode from original study\nGreen open access version of study article from arXiv\nPlanned scope for reproduction\n\n\n\n\n\nModified template to be about Shoaib and Ramamohan 2022"
  },
  {
    "objectID": "reproduction/reproduce_fig2.html",
    "href": "reproduction/reproduce_fig2.html",
    "title": "Reproducing Figure 2A-D",
    "section": "",
    "text": "Figure 2 presents results from sensitivity analysis of configuration 1.\nNote: These are created from 10 replications currently for simplicity. At 10 replications, we would expect mean values to vary only slightly from further replication numbers. Hence, if felt similar at 10, have marked as succesfully reproduced without also testing at 100 replications."
  },
  {
    "objectID": "reproduction/reproduce_fig2.html#parameters",
    "href": "reproduction/reproduce_fig2.html#parameters",
    "title": "Reproducing Figure 2A-D",
    "section": "Parameters",
    "text": "Parameters\nIn these figures, we vary:\n\nNumber of outpatients per day:\n\n170 (same as config 4)\n85\n65\n\nAverage service time for outpatients - mean (SD):\n\n0.87 (0.21) (same as config 1)\n2.5 (0.5)\n5 (1)\n\n\nTo calculate inter-arrival times from those numbers per day, based on article description and the provided patient counts and equivalent IAT, understand the method for calculation to be round(60/(n/8.5)), where n is the number of arrivals per day. As such…\n\n# Calculation of inter-arrival times\nprint(f'For 170 outpatients, use IAT (rounded to nearest int): {60/(170/8.5)}')\nprint(f'For 85 outpatients, use IAT (rounded to nearest int): {60/(85/8.5)}')\nprint(f'For 65 outpatients, use IAT (rounded to nearest int): {60/(65/8.5)}')\n\nFor 170 outpatients, use IAT (rounded to nearest int): 3.0\nFor 85 outpatients, use IAT (rounded to nearest int): 6.0\nFor 65 outpatients, use IAT (rounded to nearest int): 7.846153846153846"
  },
  {
    "objectID": "reproduction/reproduce_fig2.html#set-up",
    "href": "reproduction/reproduce_fig2.html#set-up",
    "title": "Reproducing Figure 2A-D",
    "section": "Set up",
    "text": "Set up\n\n# To run model\nimport PHC\n\n# To import results and produce figures\nimport xlrd\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# To speed up run time\nfrom multiprocessing import Pool\n\n'''\n# Additional package to record runtime of this notebook\nimport time\nstart = time.time()\n'''\n\n'\\n# Additional package to record runtime of this notebook\\nimport time\\nstart = time.time()\\n'\n\n\n\n# Paths to save image files to\noutput_folder = 'outputs'\nfig2a_path = os.path.join(output_folder, 'fig2a.png')\nfig2b_path = os.path.join(output_folder, 'fig2b.png')\nfig2c_path = os.path.join(output_folder, 'fig2c.png')\nfig2d_path = os.path.join(output_folder, 'fig2d.png')"
  },
  {
    "objectID": "reproduction/reproduce_fig2.html#run-model",
    "href": "reproduction/reproduce_fig2.html#run-model",
    "title": "Reproducing Figure 2A-D",
    "section": "Run model",
    "text": "Run model\nAs this is a variation on configuration 1 (which is the default parameters in PHC.py), we just need to input the varying number of outpatients and service time.\n\n# TODO: Run with 100 replications\n\n# Varying number of outpatients\narr_dict = [\n    {\n        'OPD_iat': 3,\n        'rep_file': 'arr170'\n    },\n    {\n        'OPD_iat': 6,\n        'rep_file': 'arr85',\n    },\n    {\n        'OPD_iat': 8,\n        'rep_file': 'arr65',\n    }\n]\n\n# Varying service time\nserv_dict = [\n    {\n        'mean': 0.87,\n        'sd': 0.21,\n        'consult_boundary_1': 0.5,  # From PHC.py\n        'consult_boundary_2': 0.3,  # From PHC.py\n        'rep_file': 'serv087'\n    },\n    {\n        'mean': 2.5,\n        'sd': 0.5,\n        'consult_boundary_1': 1,  # Guess\n        'consult_boundary_2': 1,  # Guess\n        'rep_file': 'serv25'\n    },\n    {\n        'mean': 5,\n        'sd': 1,\n        'consult_boundary_1': 2,  # From config 4\n        'consult_boundary_2': 2,  # From config 4\n        'rep_file': 'serv5'\n    }\n]\n\nCreate each combination for the reproduction\n\ndict_list = []\nfor arr in arr_dict:\n    for serv in serv_dict:\n        # Combine the dictionaries\n        comb = {**arr, **serv}\n        # Replace the file name\n        comb['rep_file'] = f'''f2_{arr['rep_file']}_{serv['rep_file']}.xls'''\n        # Save to list\n        dict_list.append(comb)\n\nlen(dict_list)\n\n9\n\n\n\n# Append 's_' to all items\nfor i, d in enumerate(dict_list):\n    dict_list[i] = {f's_{k}': v for k, v in d.items()}\n\n# Preview example\ndict_list[0]\n\n{'s_OPD_iat': 3,\n 's_rep_file': 'f2_arr170_serv087.xls',\n 's_mean': 0.87,\n 's_sd': 0.21,\n 's_consult_boundary_1': 0.5,\n 's_consult_boundary_2': 0.3}\n\n\nRun the model (with parallel processing to reduce run time)\n\n'''\n# Wrapper function to allow input of dictionary with pool\ndef wrapper(d):\n    return PHC.main(**d)\n\n# Create a process pool that uses all CPUs\nwith Pool() as pool:\n    # Run PHC.main() using each of inputs from config\n    pool.map(wrapper, dict_list)\n'''\n\n'\\n# Wrapper function to allow input of dictionary with pool\\ndef wrapper(d):\\n    return PHC.main(**d)\\n\\n# Create a process pool that uses all CPUs\\nwith Pool() as pool:\\n    # Run PHC.main() using each of inputs from config\\n    pool.map(wrapper, dict_list)\\n'"
  },
  {
    "objectID": "reproduction/reproduce_fig2.html#function-to-process-results",
    "href": "reproduction/reproduce_fig2.html#function-to-process-results",
    "title": "Reproducing Figure 2A-D",
    "section": "Function to process results",
    "text": "Function to process results\n\ndef process_results(files):\n    '''\n    Imports files in provided list and produces a single dataframe with mean\n    results from across the replications\n\n    Parameters:\n    ----------\n    files : list\n        List of file names (exc. file type) containing replication results\n\n    Returns:\n    --------\n    summary : dataframe\n        Dataframe with mean results for each model variant in file list\n    '''\n    # Empty list to store results\n    result_list = []\n\n    for f in files:\n        # Import .xls and convert to pandas dataframe\n        book = xlrd.open_workbook(os.path.join(output_folder, f'{f}.xls'))\n        result = pd.read_excel(book, header=None, index_col=0)\n\n        # Find mean from the replication\n        # Save as dataframe, dropping the duplicate rows (NCD occ twice)\n        res = pd.DataFrame({f: result.mean(axis=1)}).drop_duplicates()\n\n        # Remove index name\n        res.index.name = None\n\n        # Save to list\n        result_list.append(res)\n\n    # Combine into single dataframe\n    summary = pd.concat(result_list, axis=1)\n\n    return summary"
  },
  {
    "objectID": "reproduction/reproduce_fig2.html#create-figure-2a",
    "href": "reproduction/reproduce_fig2.html#create-figure-2a",
    "title": "Reproducing Figure 2A-D",
    "section": "Create Figure 2A",
    "text": "Create Figure 2A\n\n# Import and process results\ndata_full = process_results([\n    'f2_arr170_serv087', 'f2_arr85_serv087', 'f2_arr65_serv087',\n    'f2_arr170_serv25', 'f2_arr85_serv25', 'f2_arr65_serv25',\n    'f2_arr170_serv5', 'f2_arr85_serv5', 'f2_arr65_serv5'])\n\n# Filter to doctor utilisation\ndata_2a = data_full.loc['doc occ']\ndata_2a\n\nf2_arr170_serv087    0.311611\nf2_arr85_serv087     0.224704\nf2_arr65_serv087     0.202088\nf2_arr170_serv25     0.639213\nf2_arr85_serv25      0.390103\nf2_arr65_serv25      0.326204\nf2_arr170_serv5      1.143897\nf2_arr85_serv5       0.639603\nf2_arr65_serv5       0.517074\nName: doc occ, dtype: float64\n\n\n\ndef create_2a_2d(s, ylab, file, ylim=False):\n    '''\n    Creates Figure 2A or 2D (as both are very similar)\n\n    Parameters:\n    -----------\n    s : pd.Series\n        Series with mean result as values, and the model variant as index\n    ylab : string\n        Label for y axis\n    file : string\n        Path to save figure\n    ylim : list, optional, default False\n        If provided, gives the lower and upper limits for the Y axis\n\n    Returns:\n    --------\n    matplotlib figure \n    '''\n    # Reshape data so in appropriate format for plotting grouped bar chart\n    names = [170, 85, 65]\n    s5 = [s['f2_arr170_serv5'], s['f2_arr85_serv5'], s['f2_arr65_serv5']]\n    s25 = [s['f2_arr170_serv25'], s['f2_arr85_serv25'], s['f2_arr65_serv25']]\n    s87 = [s['f2_arr170_serv087'], s['f2_arr85_serv087'], s['f2_arr65_serv087']]\n\n    data = pd.DataFrame(\n        {'5 (1)': s5, '2.5 (0.5)': s25, '0.87 (0.21)': s87}, index=names)\n\n    # Plot data\n    ax = data.plot.bar(edgecolor='black', color='white', width=0.7)\n\n    # Add patterns\n    bars = ax.patches\n    pattern = np.repeat(['..', '+++++', '\\\\\\\\\\\\\\\\'], 3)\n    for bar, hatch in zip(bars, pattern):\n        bar.set_hatch(hatch)\n    ax.legend(title='Consultation time (min): mean (sd)')\n\n    # Adjust figure\n    plt.xlabel('Number of patients/day')\n    plt.ylabel(ylab)\n    if ylim:\n        plt.ylim(ylim)\n    plt.xticks(rotation=0)\n    ax.grid(axis='y')\n    ax.set_axisbelow(True)\n    plt.savefig(file, bbox_inches='tight')\n    plt.show()\n\n\ncreate_2a_2d(data_2a, ylab='''Doctor's utilisation''', file=fig2a_path)"
  },
  {
    "objectID": "reproduction/reproduce_fig2.html#create-figure-2b",
    "href": "reproduction/reproduce_fig2.html#create-figure-2b",
    "title": "Reproducing Figure 2A-D",
    "section": "Create Figure 2B",
    "text": "Create Figure 2B\nImport and process data - note: used 0.87 since that is PHC1 and this is described as variants on that but, as paper notes and as I’ve observed (not shown here), “the doctor’s consultation time does not impact this outcome”, so it ultimately doesn’t matter which is chosen.\n\n# Import and process results\ndata_2b = process_results([\n    'f2_arr170_serv087', 'f2_arr85_serv087', 'f2_arr65_serv087'])\n\n# Rename columns\ndata_2b.columns = (\n    data_2b.columns.str.removeprefix('f2_arr').str.removesuffix('_serv087'))\n\n# Preview data\ndata_2b.head()\n\n\n\n\n\n\n\n\n170\n85\n65\n\n\n\n\nOPD patients\n44055.900000\n22092.100000\n16668.700000\n\n\nIPD patients\n184.100000\n186.500000\n174.900000\n\n\nANC patients\n373.500000\n364.400000\n362.800000\n\n\nDel patients\n360.600000\n372.600000\n357.400000\n\n\nOPD Q wt\n0.012007\n0.007196\n0.003558\n\n\n\n\n\n\n\nProduce figure\n\nax = data_2b.loc['NCD occ'].plot.bar(\n    edgecolor='black', color='white', hatch='..')\nplt.xlabel('Number of patients/day')\nplt.ylabel('''NCD nurse's utilisation''')\nplt.ylim(0, 1.4)\nplt.xticks(rotation=0)\nax.grid(axis='y')\nax.set_axisbelow(True)\nplt.savefig(fig2b_path, bbox_inches='tight')\nplt.show()"
  },
  {
    "objectID": "reproduction/reproduce_fig2.html#create-figure-2c",
    "href": "reproduction/reproduce_fig2.html#create-figure-2c",
    "title": "Reproducing Figure 2A-D",
    "section": "Create Figure 2C",
    "text": "Create Figure 2C\nImport and process data\n\n# Import and process results\ndata_2c = process_results([\n    'f2_arr170_serv5', 'f2_arr85_serv5', 'f2_arr65_serv5'])\n\n# Rename columns\ndata_2c.columns = (\n    data_2c.columns.str.removeprefix('f2_arr').str.removesuffix('_serv5'))\n\n# Preview data\ndata_2c.head()\n\n\n\n\n\n\n\n\n170\n85\n65\n\n\n\n\nOPD patients\n44034.900000\n22059.100000\n16683.900000\n\n\nIPD patients\n180.500000\n180.700000\n181.400000\n\n\nANC patients\n369.800000\n370.700000\n366.500000\n\n\nDel patients\n371.100000\n362.000000\n362.700000\n\n\nOPD Q wt\n6.953913\n0.536441\n0.282745\n\n\n\n\n\n\n\nProduce figure\n\n# Create figure\nax = data_2c.loc['OPD Q wt'].plot.bar(\n    edgecolor='black', color='white', hatch='..')\nplt.xlabel('Number of patients/day')\nplt.ylabel('''OPD average waiting time (minutes)''')\nplt.xticks(rotation=0)\nplt.ylim(0, 8)\nax.grid(axis='y')\nax.set_axisbelow(True)\nplt.savefig(fig2c_path, bbox_inches='tight')\nplt.show()"
  },
  {
    "objectID": "reproduction/reproduce_fig2.html#create-figure-2d",
    "href": "reproduction/reproduce_fig2.html#create-figure-2d",
    "title": "Reproducing Figure 2A-D",
    "section": "Create Figure 2D",
    "text": "Create Figure 2D\n\n# Filter to pharmacy waiting time\ndata_2d = data_full.loc['Pharmacy Q wt']\ndata_2d\n\nf2_arr170_serv087    2.476096\nf2_arr85_serv087     0.459063\nf2_arr65_serv087     0.292411\nf2_arr170_serv25     2.448591\nf2_arr85_serv25      0.453829\nf2_arr65_serv25      0.284289\nf2_arr170_serv5      1.286610\nf2_arr85_serv5       0.338799\nf2_arr65_serv5       0.215271\nName: Pharmacy Q wt, dtype: float64\n\n\n\ncreate_2a_2d(data_2d, ylab='Pharmacy average waiting time (minutes)',\n             ylim=[0, 3], file=fig2d_path)"
  },
  {
    "objectID": "reproduction/reproduce_fig2.html#run-time",
    "href": "reproduction/reproduce_fig2.html#run-time",
    "title": "Reproducing Figure 2A-D",
    "section": "Run time",
    "text": "Run time\n\n'''\n# Find run time in seconds\nend = time.time()\nruntime = round(end-start)\n\n# Display converted to minutes and seconds\nprint(f'Notebook run time: {runtime//60}m {runtime%60}s')\n'''\n\n\"\\n# Find run time in seconds\\nend = time.time()\\nruntime = round(end-start)\\n\\n# Display converted to minutes and seconds\\nprint(f'Notebook run time: {runtime//60}m {runtime%60}s')\\n\""
  },
  {
    "objectID": "quarto_site/reproduction_readme.html",
    "href": "quarto_site/reproduction_readme.html",
    "title": "README for reproduction",
    "section": "",
    "text": "Please note: This is a template README and has not yet been completed\n\n\n\nTBC\n\n\n\nTBC\n\n\n\n\n\nTBC\n\n\n\nTBC\n\n\n\nTBC\n\n\n\n\nTBC\n\n\n\n\nTBC\n\n\n\nTBC"
  },
  {
    "objectID": "quarto_site/reproduction_readme.html#model-summary",
    "href": "quarto_site/reproduction_readme.html#model-summary",
    "title": "README for reproduction",
    "section": "",
    "text": "TBC"
  },
  {
    "objectID": "quarto_site/reproduction_readme.html#scope-of-the-reproduction",
    "href": "quarto_site/reproduction_readme.html#scope-of-the-reproduction",
    "title": "README for reproduction",
    "section": "",
    "text": "TBC"
  },
  {
    "objectID": "quarto_site/reproduction_readme.html#reproducing-these-results",
    "href": "quarto_site/reproduction_readme.html#reproducing-these-results",
    "title": "README for reproduction",
    "section": "",
    "text": "TBC\n\n\n\nTBC\n\n\n\nTBC"
  },
  {
    "objectID": "quarto_site/reproduction_readme.html#reproduction-specs-and-runtime",
    "href": "quarto_site/reproduction_readme.html#reproduction-specs-and-runtime",
    "title": "README for reproduction",
    "section": "",
    "text": "TBC"
  },
  {
    "objectID": "quarto_site/reproduction_readme.html#citation",
    "href": "quarto_site/reproduction_readme.html#citation",
    "title": "README for reproduction",
    "section": "",
    "text": "TBC"
  },
  {
    "objectID": "quarto_site/reproduction_readme.html#license",
    "href": "quarto_site/reproduction_readme.html#license",
    "title": "README for reproduction",
    "section": "",
    "text": "TBC"
  },
  {
    "objectID": "quarto_site/license.html",
    "href": "quarto_site/license.html",
    "title": "Open Source License",
    "section": "",
    "text": "This repository is licensed under the [license].\n\n\n\n\n\n\nView license\n\n\n\n\n\nMIT License\nCopyright (c) 2024 STARS Project Team\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n\nThis is aligned with the original study, who shared their code under [license].\n\n\n\n\n\n\nView license\n\n\n\n\n\n\n[Embedded license]\n\n\n\n\nThe original study was published in the journal “[Journal name]”. They distributed the article under [Add more details about license]\n\n\n\n\n\n\nView copyright statement from journal"
  },
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "Contributing",
    "section": "",
    "text": "🎉 Thank you for checking out our project! 🎉\nThis page contains guidelines on how to get in touch with us and potentially contribute towards this repository.\n\n\nYou can contact the researchers on this project using the provided email addresses in CITATION.cff.\n\n\n\nIf you spot an issue, you are welcome to raise this either by:\n\nUsing GitHub Issues.\nForking the repository, make your changes and submit a pull request for review."
  },
  {
    "objectID": "CONTRIBUTING.html#email",
    "href": "CONTRIBUTING.html#email",
    "title": "Contributing",
    "section": "",
    "text": "You can contact the researchers on this project using the provided email addresses in CITATION.cff."
  },
  {
    "objectID": "CONTRIBUTING.html#suggesting-changes",
    "href": "CONTRIBUTING.html#suggesting-changes",
    "title": "Contributing",
    "section": "",
    "text": "If you spot an issue, you are welcome to raise this either by:\n\nUsing GitHub Issues.\nForking the repository, make your changes and submit a pull request for review."
  },
  {
    "objectID": "logbook/posts/2024_06_24/index.html",
    "href": "logbook/posts/2024_06_24/index.html",
    "title": "Day 3",
    "section": "",
    "text": "Note\n\n\n\nSuccesful reproduction of Table 6, and start on figure 2. Total time used: 13h 49m (34.5%)\nAny references to the original study are to Shoaib and Ramamohan (2021) which is licensed under CC BY-NC-ND."
  },
  {
    "objectID": "logbook/posts/2024_06_24/index.html#different-configurations",
    "href": "logbook/posts/2024_06_24/index.html#different-configurations",
    "title": "Day 3",
    "section": "9.20-10.03, 10.11-10.22, 10.31-11.43: Different configurations",
    "text": "9.20-10.03, 10.11-10.22, 10.31-11.43: Different configurations\nGot parameters for each configuration from Table 3. Some discrepancies:\n\nConfiguration 4 (benchmark) is stated as 4 nurses in the table, but in the text, is described as having 5 nurses (1 NCD and 4 staff) - although the staff nurses are described as working alone in consecutive 8 hour shifts, which would work out to 3 nurses, so it is assumed that the standard configuration of 3 staff nurse and 1 NCD nurse (and so 4 nurses overall, as in the table) is used.\nTable 3 caption describes all configurations as having 6 inpatient and 1 labour bed - whilst Table 6 describes configuration 3 as having 0 labour room beds. However, as there is no labour arrivals, this has no impact on results, so just left as default 1 bed as per Table 3.\n\nConfiguration 3 has no arrivals for childbirth or ANC, and so Table 3 states their inter-arrival time as NaN. However, it was unclear how to set this up in the model code.\nTrying to figure how best to re-run the PHC.py script given it is set up with global variables. Based on this StackOverflow post, tried out creating all global parameters using a single class, so that - if you want to re-run and reset all global parameters - you just make a new instance of this class. Like this -\nDEFAULT_OPD_IAT = 4\nDEFAULT_DELIVERY_IAT = 1440\nDEFAULT_IPD_IAT = 2880\nDEFAULT_ANC_IAT = 1440\n\n\nclass ModelState:\n    \"\"\"\n    Class containing all global parameters (so that, if you wish to reset\n    values, you can do so easily by creating a new instance of the ModelState)\n    \"\"\"\n    def __init__(self,\n                 OPD_iat=DEFAULT_OPD_IAT,\n                 delivery_iat=DEFAULT_DELIVERY_IAT,\n                 IPD_iat=DEFAULT_IPD_IAT,\n                 ANC_iat=DEFAULT_ANC_IAT):\n        \"\"\"\n        Parameters for the simulation model.\n\n        Parameters:\n        -----------\n        OPD_iat : int\n            Inter-arrival time for OPD patients\n\n        delivery_iat : int\n        `   Inter-arrival time for labour patients\n\n        IPD_iat : int\n            Inter-arrival time for IPD patients\n\n        ANC_iat : int\n            Inter-arrival time for ANC patients\n        \"\"\"\n        self.OPD_iat = OPD_iat\n        self.delivery_iat = delivery_iat\n        self.IPD_iat = IPD_iat\n        self.ANC_iat = ANC_iat\n\n\nc1_state = ModelState()\nc1_state.__dict__\n\nc2_state = ModelState()\nc2_state.OPD_iat = 9\nc2_state.__dict__\n\nc3_state = ModelState(OPD_iat=5)\nc3_state.__dict__\nBut then reflected that this was changing the code alot, and I wasn’t 100% confident on whether it would definitely deal with all the global variables correctly (as they are repeatedly defined throughout the script).\nChat with Tom and he suggested:\n\ndir() should show global variables - but these just appear to be for notebook, so hopefully no overlap, but to check -\nReturn the value of the global variables after running the model. Then run the model again, and check the values are the same\nHe also suggested, for when there are no arrivals for two patient types, the simplest way to set this up is to set the inter-arrival time to something really really large (e.g. 10,000,000 * run time)\n\nI created a function to return global values:\ndef return_globals():\n    \"\"\"\n    Return global variables and their values from workspace. Used for\n    verifying the environment is as expected.\n\n    Returns:\n    -------\n    globals() : dict\n        Dictionary of global variables and their values\n    \"\"\"\n    return globals()\nAnd then checked if the output was consistent between different calls of the model, and this returned True, so will assume that running the model in this way is not leading to results interefering with each other between runs. See GitHub commit 16f50f7 for notebook with these results."
  },
  {
    "objectID": "logbook/posts/2024_06_24/index.html#different-configurations-continued",
    "href": "logbook/posts/2024_06_24/index.html#different-configurations-continued",
    "title": "Day 3",
    "section": "12.00-12.05, 12.17-12.57: Different configurations (continued)",
    "text": "12.00-12.05, 12.17-12.57: Different configurations (continued)\nRan the four different configurations (excluded run time from timings).\nKept setting IAT for ANC higher as was getting an average of 1 arrival (but want to be getting no arrivals), but even with IAT of 999999999999999999999999999999999*365*60*24, was still getting 1 ANC arrival with every run. Tried setting ANC() and Delivery() to comments in PHC.py, and this worked to prevent arrivals, so add True/False inputs to main() for whether these functions are called, instead of setting high IAT.\nFound differences were:\n\nMean OPD queue length was very different for all configuration compared with Table 6.\nLots of the benchmark case results looked very different to Table 6.\n\nSpent a while looking for why this might be, but not yet figured out."
  },
  {
    "objectID": "logbook/posts/2024_06_24/index.html#problem-solving-benchmark-model",
    "href": "logbook/posts/2024_06_24/index.html#problem-solving-benchmark-model",
    "title": "Day 3",
    "section": "13.55-14.30: Problem-solving benchmark model",
    "text": "13.55-14.30: Problem-solving benchmark model\nTo ensure it is not an error I’ve introduced, I copied the original PHC.py and modified it directly (the only change from config 1 that I have identified from the paper is that the OPD IAT is 3 instead of 4), and to produce both results spreadsheets. See GitHub commit 892cca4. This came out looking the same as my other run (e.g. doctor utilisation around 0.31 instead of 1.14).\nHence, wondered if the issue was in parameterising of model, so looked back over the paper. It is described as differing from the archetypal/generic model in two ways (not just one). I have only changed outpatient load (OPD IAT 4 to 3)\n\n‘Note that this benchmark configuration differs from the archetypal configuration only in the outpatient load and the doctor’s consultation time for outpatients.’ , and had not spotted change in consultation time in the tables.\nThe consultation time for the benchmark model: “we have assumed the consultation time to be normally distributed with a mean of 5 minutes and standard deviation of 1 minute with a lower bound fixed at 2 minutes”\nAs in Table 4, the normal OPD consultation time is normally distribution with mean 0.87 and standard deviation of 0.21\n\nAmended mean and sd, and set consultation boundary as a modifiable parameter (with consult_boundary_1 and 2, as the default boundary provided in the script varied depending on whether it was warm-up or not, between 0.5 and 0.3).\nThis pretty much fixed the issue - the only large difference for the benchmark model is now as for the other configurations: mean OPD queue length."
  },
  {
    "objectID": "logbook/posts/2024_06_24/index.html#problem-solving-mean-opd-queue-length",
    "href": "logbook/posts/2024_06_24/index.html#problem-solving-mean-opd-queue-length",
    "title": "Day 3",
    "section": "14.36-14.53: Problem-solving mean OPD queue length",
    "text": "14.36-14.53: Problem-solving mean OPD queue length\nChecked example of a result in full .xlsx output for config 1 from a previous commit, but this matched the model output, which itself, was very similar to the paper output.\nHence, instead ran config 4 but enabled full result spreadsheet to be produced. That output 0.833 for Mean length of OPD queue, similar to Table 6’s 0.817 and unlike my previously calculated 6.932062.\nLooking at the replication spreadsheet, I realised there were two OPD q len rows:\n\nOPD q len (with values around 7)\n\nCalculated from OPD_q__list\nThat is created by OPD_q__list.append(np.mean(an_list)), and an_list is delivery patients\n\nopd q len (with values around 0.8)\n\nCalculated from OPD_q_length_list.\nThat is created by OPD_q_length_list.append(waitingline_OPD.length.mean())\n\n\nHence, given the values match, and how it was created, the latter is evidently the appropriate row to use. Amended reproduce.ipynb to use that row, and now results match up, with no concerning deviation."
  },
  {
    "objectID": "logbook/posts/2024_06_24/index.html#add-sd-to-table-6",
    "href": "logbook/posts/2024_06_24/index.html#add-sd-to-table-6",
    "title": "Day 3",
    "section": "15.34-16.02 : Add SD to Table 6",
    "text": "15.34-16.02 : Add SD to Table 6\nAdd standard deviation. Some percent change seem large as it’s comparing very small number - but actual change between the model and table 6 all are small enough that I feel happy to say this has been successfully reproduced for the mean values.\nWill run 100 replications later, and confirm whether standard deviations are similar - but anticipate to take a while, so will work on something else for remainder of day, as not got time to run them all now.\nAs the long run-time prevents me from checking this now, I will not yet timestamp this as complete."
  },
  {
    "objectID": "logbook/posts/2024_06_24/index.html#starting-on-figure-2a-d",
    "href": "logbook/posts/2024_06_24/index.html#starting-on-figure-2a-d",
    "title": "Day 3",
    "section": "16.13-17.00: Starting on Figure 2A-D",
    "text": "16.13-17.00: Starting on Figure 2A-D\nFigure 2 presents results from sensitivity analysis of configuration 1.\nIt varies:\n\nNumber of outpatients per day:\n\n170 (same as config 4) = OPD IAT 3\n85\n65\n\nAverage service time for outpatients - mean (SD):\n\n0.87 (0.21) (same as config 1)\n2.5 (0.5)\n5 (1)\n\n\nIt states that “estimation of the outpatient arrival rate for this configuration is described in detail in Section 3.3.1”. Hence, looked back at provided times and patient counts in the Tables…\n\nConfig 1: 130 arrivals in a day and IAT of 4\nConfig 2/3: 60 arrivals in a day and IAT of 9\nConfig 4: 170 arrivals in a day and IAT of 3\n\nIn order to get those times:\n\nprint((60/4)*8.6666666666666666666666666666666)\nprint((60/9)*9)\nprint((60/3)*8.5)\n\n130.0\n60.0\n170.0\n\n\nCan see that, in order to get each of the times, the hours per day vary from 8.5 to 9. As such, it is unclear how I should calculate IAT for 85 and 65 per day, due to this variation. It is assumed that this is likely related to rounding?\nThen looked to section 3.3.1 about this in the paper, Shoaib and Ramamohan (2021):\n\n“The average interarrival times (and consequently the average number of patients) at each configuration were estimated in the following manner. The number of outpatients visiting configuration 1 PHCs (PHCs 1, 5, and 9) range from 80 to 150 patients per day. These include patients visiting for the first time for a given case of illness as well as patients visiting for follow-up consultations on a previous case. Thus we assumed that approximately 125 patients visit on a given day for these PHC configurations, which include 90 first-visit patients, 20% patients on their first follow-up, and 10% visiting for their second follow-up, yield approximately 126 patients. Therefore, the interarrival time of 4 minutes at configuration 1 PHCs corresponds to first-time visits, with follow-up visits scheduled at the same time on any day between the next 3 and 8 days.”\n\nThese values differ from the table - so looking again with these:\n\nConfig 1: 125 or 126 arrivals and IAT 4\nConfig 2/3: 55 arrivals and IAT 9\n\n\nprint((60/4)*8.33333333333333333)\nprint((60/4)*8.4)\nprint((60/9)*8.25)\n\n125.00000000000001\n126.0\n55.0\n\n\nRegarding the number of hours described in the article, this is described as “6 hours per day” for the outpatients - which differs to the 8.25 hours to 9 that align with the provided patient numbers and inter-arrival times.\nAssuming this variation is simply related to rounding the IAT - as if we calculate these values based on there being 8.5 hours per day then round the IAT, we get the same results…\n\n# IAT 3. Arrivals 170\nprint(60/(170/8.5))\n\n# IAT 4. Arrivals 125-130\nprint(60/(125/8.5))\nprint(60/(130/8.5))\n\n# IAT 9. Arrivals 55-60\nprint(60/(55/8.5))\nprint(60/(60/8.5))\n\n3.0\n4.08\n3.923076923076923\n9.272727272727273\n8.5\n\n\nAs such, the inter-arrival times used were calculated as 3, 6 and 8…\n\n# 170, 85 and 65 arrivals\nprint(60/(170/8.5))\nprint(60/(85/8.5))\nprint(60/(65/8.5))\n\n3.0\n6.0\n7.846153846153846"
  },
  {
    "objectID": "logbook/posts/2024_06_24/index.html#reflections-from-troubleshooting-today",
    "href": "logbook/posts/2024_06_24/index.html#reflections-from-troubleshooting-today",
    "title": "Day 3",
    "section": "Reflections from troubleshooting today",
    "text": "Reflections from troubleshooting today\n\n\n\n\n\n\nChallenges today\n\n\n\nAdapting model to run model programmatically (rather than having to directly change the parameters in the script itself)\nDifficulty identifying parameters of scenarios (when not all captured in a single table, but in combination with article text) (and when not provided in the script).\nTime spent processing results into desired tables and/or figures (when not already created by the script).\nUncertainty on model parameters if not provided and calculation unclear (inter-arrival time)."
  },
  {
    "objectID": "logbook/posts/2024_06_24/index.html#timings",
    "href": "logbook/posts/2024_06_24/index.html#timings",
    "title": "Day 3",
    "section": "Timings",
    "text": "Timings\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 531\n\n# Times from today\ntimes = [\n    ('9.20', '10.03'),\n    ('10.11', '10.22'),\n    ('10.31', '11.43'),\n    ('12.00', '12.05'),\n    ('12.17', '12.57'),\n    ('13.55', '14.30'),\n    ('14.36', '14.53'),\n    ('15.34', '16.02'),\n    ('16.13', '17.00')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 298m, or 4h 58m\nTotal used to date: 829m, or 13h 49m\nTime remaining: 1571m, or 26h 11m\nUsed 34.5% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_06_20/index.html",
    "href": "logbook/posts/2024_06_20/index.html",
    "title": "Day 1",
    "section": "",
    "text": "Note\n\n\n\nSet up and scope. Total time used: 3h 59m (10.0%)"
  },
  {
    "objectID": "logbook/posts/2024_06_20/index.html#set-up-repository",
    "href": "logbook/posts/2024_06_20/index.html#set-up-repository",
    "title": "Day 1",
    "section": "10.16-10.35: Set up repository",
    "text": "10.16-10.35: Set up repository\n\nCreate repository from template\nSet up environment\nSet up site on GitHub pages (quarto publish gh-pages)\nAmendments to files to reflect current paper (e.g. author name, citation):\n\nREADME.md\nquarto site index.qmd\nCITATION.cff\n_quarto.yml"
  },
  {
    "objectID": "logbook/posts/2024_06_20/index.html#upload-code-to-repository-and-check-license",
    "href": "logbook/posts/2024_06_20/index.html#upload-code-to-repository-and-check-license",
    "title": "Day 1",
    "section": "10.41-10.43: Upload code to repository and check license",
    "text": "10.41-10.43: Upload code to repository and check license\nModel code from: https://github.com/shoaibiocl/PHC-. Downloaded repository and copied folder PHC--main into original_study/.\nThey shared under MIT license, so no amendments to our license required."
  },
  {
    "objectID": "logbook/posts/2024_06_20/index.html#upload-journal-article-to-repository-and-compare-between-arxiv-and-simulation-version",
    "href": "logbook/posts/2024_06_20/index.html#upload-journal-article-to-repository-and-compare-between-arxiv-and-simulation-version",
    "title": "Day 1",
    "section": "10.44-11.15: Upload journal article to repository and compare between arxiv and simulation version",
    "text": "10.44-11.15: Upload journal article to repository and compare between arxiv and simulation version\nArticle is published with SIMULATION and is not open access: https://journals.sagepub.com/doi/10.1177/00375497211030931 (https://doi.org/10.1177/00375497211030931). Button to request reuse takes you to reuse which has charges for reuse.\nSearched for green open access version of article and identified pre-print on arxiv: https://arxiv.org/abs/2104.12492 (https://doi.org/10.48550/arXiv.2104.12492). That is shared via CC BY-NC-ND 4.0. This means we can:\n\nShare the article (inc. the images from the article)\nMust give attribution - appropriate credit, provide link to license, and indicate if changes are made\nND (NoDerivatives) - so cannot make any modifications to the article or images (inc. e.g. colour changes etc) - which is fine as don’t plan to do so\n\nAs such, saved the article as preprint.pdf within original_study/.\nSIMULATION first published online 18 July 2021. The pre-print was first submit 15 Feb 2021 with second version 21 June 2021 (after the SIMULATION date, hence anticipating should be similar). Glanced between the pre-print and publication in SIMULATION to look for differences:\n\nText - broadly looks very similar, spotted one difference (“Next, for assigning ages to outpatients” v.s. “Later, for assigning ages to outpatients”), and so there may be more.\nTables and figures - contents looked similar, spotted differences:\n\nTable 2 + 3 + 4 + 5 + 6 + C.1 footnotes - more abbreviations provided in SIMULATION paper\nFormatting differences for tables\nFigures provided seperately in pre-print (e.g. 2a vs 2b vs 2c vs 2d rather than all as a single figure - although that does make them easier to read when they are seperate)\n\n\nEmbed in study_publication.qmd with links."
  },
  {
    "objectID": "logbook/posts/2024_06_20/index.html#detailed-comparison-of-exercept-from-the-two-papers",
    "href": "logbook/posts/2024_06_20/index.html#detailed-comparison-of-exercept-from-the-two-papers",
    "title": "Day 1",
    "section": "11.40-12.00: Detailed comparison of exercept from the two papers",
    "text": "11.40-12.00: Detailed comparison of exercept from the two papers\nDecided to do a more thorough comparison of the text content, to confirm that the arxiv version was appropriate to use. Converted files from arxiv and simulation to text using pdftotext on the command line. Then copied section-by-section into https://text-compare.com/ to look carefully for differences.\nCompared Abstract through to section 3.3. Found no cause for concern. Only differences were in spelling and grammar, or minor differences in phrasing (e.g. abbreviating words, abbreviating numbers, “etc” v.s. “among others”, “et al.” vs using second author surname). As such, stopped comparing at this point.\n\n\n\n\n\n\nReflection\n\n\n\nTook a while to do this stage (for simplicity, including all set-up in timing, but worth being aware that this has added a fair bit of extra time to if we could have just used the original article, so worth reflecting on whether should definitely be included in time, or if be aware of set-up times but perhaps would want to subtract from the overall times?)"
  },
  {
    "objectID": "logbook/posts/2024_06_20/index.html#add-proper-citations-to-study_publication.qmd",
    "href": "logbook/posts/2024_06_20/index.html#add-proper-citations-to-study_publication.qmd",
    "title": "Day 1",
    "section": "13.10-13.15: Add proper citations to study_publication.qmd",
    "text": "13.10-13.15: Add proper citations to study_publication.qmd\nUpdated references.bib to include citations for SIMULATION and arXiv sources, and included those on study_publication.qmd, as well as a link to the license."
  },
  {
    "objectID": "logbook/posts/2024_06_20/index.html#read-journal-article",
    "href": "logbook/posts/2024_06_20/index.html#read-journal-article",
    "title": "Day 1",
    "section": "13.18-14.00, 14.15-14.36: Read journal article",
    "text": "13.18-14.00, 14.15-14.36: Read journal article\nTook some notes whilst reading the first part of the paper, but mostly just highlighted the paper after that. Not shared highlights as license under CC BY-NC-ND so doesn’t allow modifications.\nTook some initial notes on scope which have incorporated in scope section below\n\n\n\n\n\n\nReading notes\n\n\n\n\n\nDiscrete-event simulations to model primary health centres (PHC) in India\n\nPHC are first point of contact with trained doctor\n\nRationale:\n\nEfforts in India towards “establishing new PHCs, upgrading existing primary health infrastructure, and increasing medical personnel numbers”, but “their operational effectiveness and influence on improving public health accessibility is not adequately quantified.” and there is a need for “assessment of theoperational aspects of these facilities before more resources are invested in their upgradation and/or establishing new PHC infrastructure.”\nProvides “template for developing models of similar primary/secondary healthcare facilities”\n“limited literature regarding whole facility simulation models that cater to multiple patient types with distinct clinical and operational flows through the facility (similar to PHCs). This is likely because most healthcare DES studies are undertaken to help analyse and/or solve specific problems associated with a facility, whereas our study aims to contribute towards establishing the computational infrastructure required to analyse the public health system in a region.”\n“our research contribution here involves the inclusion of limited inpatient care and childbirth care in our PHC models inaddition to modelling general OPD consultations and emergency cases”\n“our literature search did not yield any study that computationally examined: a) PHC operations, and b) how their operational performance would respond to changes in demand and/or capacity. Further, there appears to be very limited healthcare facility simulations in general in the Indian context. Our study aims to address these gaps.”\n\nModel design:\n\nVisited “multiple PHCs in a semi- urban/rural district in North India and collecting data regarding their operational patterns.”\nThen designed “archetypal or ‘generic’ DES model of PHC operations based on the commonalities” and “adapt (reuse with modification) this generic model to represent the different operational configurations encountered in our visits.”\nAlso compared with “benchmark configuration conforming to government-mandated operational guidelines, with demand estimated from disease burden data and service times closer to international estimates, which are significantly higher than observed service times at the PHCs.”\n\nFour patient types:\n\nOutpatients\nInpatients and/or emergency (“requiring care and observation for brief periods” e.g. injuries, diarrhoea)\nChildbirth\nAntenatal\n\nResources:\n\nDoctors (1 or 2, depending on configuration)\nNurses: (a) non-communicable disease trained, present during outpatient hours (b) staff nurses, for inpatient/emergency/childbird\nPharmacists (outpatient hours)\nLaboratory technician (outpatient hours)\nInpatient and childbirth beds\n\nFocus:\n\n“operational outcomes such as the average waiting time of patients for various resources (e.g., doctors, pharmacy, clinical laboratory), resource utilisation levels across the PHC, and the proportions of childbirth patients who wait longer than a certain time threshold.”\n“experiments to quantify how these PHC configurations respond to changes (increases) in demand, and identify solutions to potentially improve operational efficiency under conditions of high demand.”"
  },
  {
    "objectID": "logbook/posts/2024_06_20/index.html#defining-scope",
    "href": "logbook/posts/2024_06_20/index.html#defining-scope",
    "title": "Day 1",
    "section": "14.37-15.01: Defining scope",
    "text": "14.37-15.01: Defining scope\nTables:\n\nTable 1 - n/a\nTable 2 - n/a\nTable 3 - n/a\nTable 4 - n/a\nTable 5 - no - about internal validation of model rather than results of model - don’t think focus is on validation of parameters, but instead, outcome of model built on those parameters, so would class as not in scope\nTable 6 - definitely in scope!\n\nFigures:\n\nFigure 1 - n/a\nFigure 2 - definitely in scope - but uncertain over whether to treat A / B / C / D as seperate figures or as one figure? In arXiv paper, they are presented quite seperately (although they are put together more in the simulation paper).\nFigure 3 - as for figure 2\nFigure 4 - in scope\n\nResults from the abstract or results section that I can’t currently spot as being covered by the tables and figures:\n\n\n\n\n\n\n\n\nSections quoted from Shoaib and Ramamohan (2021)\nPrecise result to be reproduced\nThoughts on whether to include in scope\n\n\n\n\n4.3 “We also note that waiting times for outpatient-related resources (laboratory, OPD consultation, etc. - not depicted in Figures 3a – 3d) increase marginally because the associated resources are also required by inpatient/childbirth/ANC cases, which increase in number in the above scenarios”\nNo - just marginal increase\nNo? Could argue not in scope, as all you’re aiming for is “seeing a marginal increase” - but likewise, if you saw the opposite of that, you could argue it’s not being reproduced. However, leaning towards the latter as nothing precise\n\n\n4.3.1 “To address this, we experimented with letting the staff nurse (whose utilisation is approximately 32%) take over the administrative work. This led to a 12% drop in the utilisation level, which implied that the doctor’s utilisation still exceeded 100%. Implementing this measure resulted in increasing the staff nurse utilisation to nearly 40%.”\nStaff nurse does all administrative work (none to doctor). Look at impact on doctor’s utilisation. When have outpatient load 170 patients per day.\nMaybe? - depends if I have interpreted the described scenario correctly\n\n\n4.3.1 “then considered a situation wherein the staff nurses require minimal intervention in childbirth cases. We assumed that in 50% of childbirth cases, staff nurses require no intervention by the doctor; require only one- third of the typical amount of intervention in 30% of cases, and require full intervention in the remaining 20% of cases. This led to a decrease of the doctor’s utilisation to 101% (a further decrease of approximately 1%), and an increase in the nurse’s utilisation to 40%.”\n50% childbirth have no doctor. 30% have one-third of typical amount of doctor intervention. 20% have full doctor intervention. Look at doctor and nurse utilisation. Normal doctor attendance described in 3.3.3 is that, if doctor is available, patient is attended by both a doctor and a staff nurse - and if not available, then they attend once available, with first-come first-serve alongside inpatient. In Table 4, can see doctor childbirth service time is from uniform distribution with min 30 max 60.\nYes? Think it might be in scope, and has precise results to reproduce\n\n\n4.3.1 “investigated the effect of stationing an additional doctor in the PHC. This yielded an average utilisation of well below 100% for each doctor.”\nNo precise result\nNo? Potentially not as doesn’t have a precise result, just “well below 100%”\n\n\n4.3.2 “We also observe that if the number of beds is reduced to four from six, the utilisation level is observed to be approximately thirty-three percent even under higher demand conditions (two inpatient and childbirth cases/day).”\nApx. 33% inpatient bed utilisation when there are four bed and there are 2 inpatient and childbirth cases per day\nMaybe? Only gives an approximate result which it says holders “even under higher demand” but is not specific to those conditions, and so could be a few percent different or more, depending on interpretation of “approximate”. Hence, not sure if precise enough to reproduce.\n\n\n4.3.3 “When the administrative work alone is assigned to the staff nurse the average utilisation of the NCD nurse decreases to 100%”\nOutpatient IAT 3 min and administrative work just performed by staff nurse (and not NCD nurse), NCD nurse utilisation 100%\nMaybe? Might be precise enough?\n\n\n4.3.3 “Further, in addition to the administrative work when the staff nurse assisted for NCD checks (for 10% cases) the utilisation of NCD nurse dropped to 71%.”\nIf 10% cases assigned to staff nurse instead of NCD, when outpatient IAT 3 min, NCD utilisation is 71%\nMaybe? Might be precise enough, assuming I’ve interpreted scenario correctly?\n\n\n\nAppendix C - not relevant, focused on validation."
  },
  {
    "objectID": "logbook/posts/2024_06_20/index.html#discussed-scope-with-tom",
    "href": "logbook/posts/2024_06_20/index.html#discussed-scope-with-tom",
    "title": "Day 1",
    "section": "15.15-15.36: Discussed scope with Tom",
    "text": "15.15-15.36: Discussed scope with Tom\n\nTreat sub-figures as seperate figures.\nFor marginal/non-precise results in text, decided to include in scope and to see if we get a result that meets our judgement (e.g. our judgement of “big change” and so on), but if we think it doesn’t, can check with the original study authors if they know what the actual change they observed was, to confirm if the result is definitely different or just down to subjective differences\nAgreed on how I had interpreted some of the scenarios described in the text\nSuggested including results from the discussion as well, and found one more result, but agree it was covered by the text - “For example, as the sensitivity analyses with consultation times for doctors closer to international levels showed, PHC resources become stressed even when only 30% of current healthcare demand is addressed at a PHC. Further, we also find that a significant proportion of childbirth patients (approximately 16- 28% when the number of childbirth cases/day varies from 1-2) wait longer than two hours before receiving admission into the childbirth facility (bed) at a PHC”\nAfter, Tom double-checked discussion again and spotted no further items"
  },
  {
    "objectID": "logbook/posts/2024_06_20/index.html#uploading-items-from-scope",
    "href": "logbook/posts/2024_06_20/index.html#uploading-items-from-scope",
    "title": "Day 1",
    "section": "15.59-16.53: Uploading items from scope",
    "text": "15.59-16.53: Uploading items from scope\nUploading:\n\nFigures as images\nTables as images\nTables as CSV\nResults from text as CSV\n\nDisplaying uploads within scope.qmd, along with description of decision."
  },
  {
    "objectID": "logbook/posts/2024_06_20/index.html#timings",
    "href": "logbook/posts/2024_06_20/index.html#timings",
    "title": "Day 1",
    "section": "Timings",
    "text": "Timings\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 0\n\n# Times from today\ntimes = [\n    ('10.16', '10.35'),\n    ('10.41', '10.43'),\n    ('10.44', '11.15'),\n    ('11.40', '12.00'),\n    ('13.10', '13.15'),\n    ('13.18', '14.00'),\n    ('14.15', '14.36'),\n    ('14.37', '15.01'),\n    ('15.15', '15.36'),\n    ('15.59', '16.53')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 239m, or 3h 59m\nTotal used to date: 239m, or 3h 59m\nTime remaining: 2161m, or 36h 1m\nUsed 10.0% of 40 hours max"
  },
  {
    "objectID": "evaluation/reporting.html",
    "href": "evaluation/reporting.html",
    "title": "Reporting guidelines",
    "section": "",
    "text": "Please note: This is a template page and has not yet been completed\nThis page evaluates the extent to which the journal article meets the criteria from two discrete-event simulation study reporting guidelines:"
  },
  {
    "objectID": "evaluation/reporting.html#stress-des",
    "href": "evaluation/reporting.html#stress-des",
    "title": "Reporting guidelines",
    "section": "STRESS-DES",
    "text": "STRESS-DES\nOf the 24 items in the checklist:\n\n\nX were met fully (✅)\nX were partially met (🟡)\nX were not met (❌)\nX were not applicable (N/A)\n\n\n\n\n\n\n\n\n\n\n\nItem\nRecommendation\nMet by study?\nEvidence\n\n\n\n\nObjectives\n\n\n\n\n\n1.1 Purpose of the model\nExplain the background and objectives for the model\n\n\n\n\n1.2 Model outputs\nDefine all quantitative performance measures that are reported, using equations where necessary. Specify how and when they are calculated during the model run along with how any measures of error such as confidence intervals are calculated.\n\n\n\n\n1.3 Experimentation aims\nIf the model has been used for experimentation, state the objectives that it was used to investigate.(A) Scenario based analysis – Provide a name and description for each scenario, providing a rationale for the choice of scenarios and ensure that item 2.3 (below) is completed.(B) Design of experiments – Provide details of the overall design of the experiments with reference to performance measures and their parameters (provide further details in data below).(C) Simulation Optimisation – (if appropriate) Provide full details of what is to be optimised, the parameters that were included and the algorithm(s) that was be used. Where possible provide a citation of the algorithm(s).\n\n\n\n\nLogic\n\n\n\n\n\n2.1 Base model overview diagram\nDescribe the base model using appropriate diagrams and description. This could include one or more process flow, activity cycle or equivalent diagrams sufficient to describe the model to readers. Avoid complicated diagrams in the main text. The goal is to describe the breadth and depth of the model with respect to the system being studied.\n\n\n\n\n2.2 Base model logic\nGive details of the base model logic. Give additional model logic details sufficient to communicate to the reader how the model works.\n\n\n\n\n2.3 Scenario logic\nGive details of the logical difference between the base case model and scenarios (if any). This could be incorporated as text or where differences are substantial could be incorporated in the same manner as 2.2.\n\n\n\n\n2.4 Algorithms\nProvide further detail on any algorithms in the model that (for example) mimic complex or manual processes in the real world (i.e. scheduling of arrivals/ appointments/ operations/ maintenance, operation of a conveyor system, machine breakdowns, etc.). Sufficient detail should be included (or referred to in other published work) for the algorithms to be reproducible. Pseudo-code may be used to describe an algorithm.\n\n\n\n\n2.5.1 Components - entities\nGive details of all entities within the simulation including a description of their role in the model and a description of all their attributes.\n\n\n\n\n2.5.2 Components - activities\nDescribe the activities that entities engage in within the model. Provide details of entity routing into and out of the activity.\n\n\n\n\n2.5.3 Components - resources\nList all the resources included within the model and which activities make use of them.\n\n\n\n\n2.5.4 Components - queues\nGive details of the assumed queuing discipline used in the model (e.g. First in First Out, Last in First Out, prioritisation, etc.). Where one or more queues have a different discipline from the rest, provide a list of queues, indicating the queuing discipline used for each. If reneging, balking or jockeying occur, etc., provide details of the rules. Detail any delays or capacity constraints on the queues.\n\n\n\n\n2.5.5 Components - entry/exit points\nGive details of the model boundaries i.e. all arrival and exit points of entities. Detail the arrival mechanism (e.g. ‘thinning’ to mimic a non-homogenous Poisson process or balking)\n\n\n\n\nData\n\n\n\n\n\n3.1 Data sources\nList and detail all data sources. Sources may include:• Interviews with stakeholders,• Samples of routinely collected data,• Prospectively collected samples for the purpose of the simulation study,• Public domain data published in either academic or organisational literature. Provide, where possible, the link and DOI to the data or reference to published literature.All data source descriptions should include details of the sample size, sample date ranges and use within the study.\n\n\n\n\n3.2 Pre-processing\nProvide details of any data manipulation that has taken place before its use in the simulation, e.g. interpolation to account for missing data or the removal of outliers.\n\n\n\n\n3.3 Input parameters\nList all input variables in the model. Provide a description of their use and include parameter values. For stochastic inputs provide details of any continuous, discrete or empirical distributions used along with all associated parameters. Give details of all time dependent parameters and correlation.Clearly state:• Base case data• Data use in experimentation, where different from the base case.• Where optimisation or design of experiments has been used, state the range of values that parameters can take.• Where theoretical distributions are used, state how these were selected and prioritised above other candidate distributions.\n\n\n\n\n3.4 Assumptions\nWhere data or knowledge of the real system is unavailable what assumptions are included in the model? This might include parameter values, distributions or routing logic within the model.\n\n\n\n\nExperimentation\n\n\n\n\n\n4.1 Initialisation\nReport if the system modelled is terminating or non-terminating. State if a warm-up period has been used, its length and the analysis method used to select it. For terminating systems state the stopping condition.State what if any initial model conditions have been included, e.g., pre-loaded queues and activities. Report whether initialisation of these variables is deterministic or stochastic.\n\n\n\n\n4.2 Run length\nDetail the run length of the simulation model and time units.\n\n\n\n\n4.3 Estimation approach\nState the method used to account for the stochasticity: For example, two common methods are multiple replications or batch means. Where multiple replications have been used, state the number of replications and for batch means, indicate the batch length and whether the batch means procedure is standard, spaced or overlapping. For both procedures provide a justification for the methods used and the number of replications/size of batches.\n\n\n\n\nImplementation\n\n\n\n\n\n5.1 Software or programming language\nState the operating system and version and build number.State the name, version and build number of commercial or open source DES software that the model is implemented in.State the name and version of general-purpose programming languages used (e.g. Python 3.5).Where frameworks and libraries have been used provide all details including version numbers.\n\n\n\n\n5.2 Random sampling\nState the algorithm used to generate random samples in the software/programming language used e.g. Mersenne Twister.If common random numbers are used, state how seeds (or random number streams) are distributed among sampling processes.\n\n\n\n\n5.3 Model execution\nState the event processing mechanism used e.g. three phase, event, activity, process interaction.Note that in some commercial software the event processing mechanism may not be published. In these cases authors should adhere to item 5.1 software recommendations.State all priority rules included if entities/activities compete for resources.If the model is parallel, distributed and/or use grid or cloud computing, etc., state and preferably reference the technology used. For parallel and distributed simulations the time management algorithms used. If the HLA is used then state the version of the standard, which run-time infrastructure (and version), and any supporting documents (FOMs, etc.)\n\n\n\n\n5.4 System specification\nState the model run time and specification of hardware used. This is particularly important for large scale models that require substantial computing power. For parallel, distributed and/or use grid or cloud computing, etc. state the details of all systems used in the implementation (processors, network, etc.)\n\n\n\n\nCode access\n\n\n\n\n\n6.1 Computer model sharing statement\nDescribe how someone could obtain the model described in the paper, the simulation software and any other associated software (or hardware) needed to reproduce the results. Provide, where possible, the link and DOIs to these."
  },
  {
    "objectID": "evaluation/reporting.html#des-checklist-derived-from-ispor-sdm",
    "href": "evaluation/reporting.html#des-checklist-derived-from-ispor-sdm",
    "title": "Reporting guidelines",
    "section": "DES checklist derived from ISPOR-SDM",
    "text": "DES checklist derived from ISPOR-SDM\nOf the 18 items in the checklist:\n\n\nX were met fully (✅)\nX was partially met (🟡)\nX was not met (❌)\nX were not applicable (N/A)\n\n\n\n\n\n\n\n\n\n\n\nItem\nAssessed if…\nMet by study?\nEvidence/location\n\n\n\n\nModel conceptualisation\n\n\n\n\n\n1 Is the focused health-related decision problem clarified?\n…the decision problem under investigation was defined. DES studies included different types of decision problems, eg, those listed in previously developed taxonomies.\n\n\n\n\n2 Is the modeled healthcare setting/health condition clarified?\n…the physical context/scope (eg, a certain healthcare unit or a broader system) or disease spectrum simulated was described.\n\n\n\n\n3 Is the model structure described?\n…the model’s conceptual structure was described in the form of either graphical or text presentation.\n\n\n\n\n4 Is the time horizon given?\n…the time period covered by the simulation was reported.\n\n\n\n\n5 Are all simulated strategies/scenarios specified?\n…the comparators under test were described in terms of their components, corresponding variations, etc\n\n\n\n\n6 Is the target population described?\n…the entities simulated and their main attributes were characterized.\n\n\n\n\nParamaterisation and uncertainty assessment\n\n\n\n\n\n7 Are data sources informing parameter estimations provided?\n…the sources of all data used to inform model inputs were reported.\n\n\n\n\n8 Are the parameters used to populate model frameworks specified?\n…all relevant parameters fed into model frameworks were disclosed.\n\n\n\n\n9 Are model uncertainties discussed?\n…the uncertainty surrounding parameter estimations and adopted statistical methods (eg, 95% confidence intervals or possibility distributions) were reported.\n\n\n\n\n10 Are sensitivity analyses performed and reported?\n…the robustness of model outputs to input uncertainties was examined, for example via deterministic (based on parameters’ plausible ranges) or probabilistic (based on a priori-defined probability distributions) sensitivity analyses, or both.\n\n\n\n\nValidation\n\n\n\n\n\n11 Is face validity evaluated and reported?\n…it was reported that the model was subjected to the examination on how well model designs correspond to the reality and intuitions. It was assumed that this type of validation should be conducted by external evaluators with no stake in the study.\n\n\n\n\n12 Is cross validation performed and reported\n…comparison across similar modeling studies which deal with the same decision problem was undertaken.\n\n\n\n\n13 Is external validation performed and reported?\n…the modeler(s) examined how well the model’s results match the empirical data of an actual event modeled.\n\n\n\n\n14 Is predictive validation performed or attempted?\n…the modeler(s) examined the consistency of a model’s predictions of a future event and the actual outcomes in the future. If this was not undertaken, it was assessed whether the reasons were discussed.\n\n\n\n\nGeneralisability and stakeholder involvement\n\n\n\n\n\n15 Is the model generalizability issue discussed?\n…the modeler(s) discussed the potential of the resulting model for being applicable to other settings/populations (single/multiple application).\n\n\n\n\n16 Are decision makers or other stakeholders involved in modeling?\n…the modeler(s) reported in which part throughout the modeling process decision makers and other stakeholders (eg, subject experts) were engaged.\n\n\n\n\n17 Is the source of funding stated?\n…the sponsorship of the study was indicated.\n\n\n\n\n18 Are model limitations discussed?\n…limitations of the assessed model, especially limitations of interest to decision makers, were discussed."
  },
  {
    "objectID": "evaluation/badges.html",
    "href": "evaluation/badges.html",
    "title": "Journal badges",
    "section": "",
    "text": "Please note: This is a template page and has not yet been completed, so all criteria are currently set as unmet (❌)\nThis page evaluates the extent to which the author-published research artefacts meet the criteria of badges related to reproducibility from various organisations and journals.\nCaveat: Please note that these criteria are based on available information about each badge online, and that we have likely differences in our procedure (e.g. allowed troubleshooting for execution and reproduction, not under tight time pressure to complete). Moreover, we focus only on reproduction of the discrete-event simulation, and not on other aspects of the article. We cannot guarantee that the badges below would have been awarded in practice by these journals."
  },
  {
    "objectID": "evaluation/badges.html#criteria",
    "href": "evaluation/badges.html#criteria",
    "title": "Journal badges",
    "section": "Criteria",
    "text": "Criteria\n\n\nCode\nfrom IPython.display import display, Markdown\nimport numpy as np\nimport pandas as pd\n\n# Criteria and their definitions\ncriteria = {\n    'archive': 'Stored in a permanent archive that is publicly and openly accessible',\n    'id': 'Has a persistent identifier',\n    'license': 'Includes an open license',\n    'relevant': '''Arefacts are relevant to and contribute to the article's results''',\n    'complete': 'Complete set of materials shared (as would be needed to fully reproduce article)',\n    'structure': 'Artefacts are well structured/organised (e.g. to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)',\n    'documentation_sufficient': 'Artefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)',\n    'documentation_careful': 'Artefacts are carefully documented (more than sufficient - i.e. to the extent that reuse and repurposing is facilitated - e.g. changing parameters, reusing for own purpose)',\n    # This criteria is kept seperate to documentation_careful, as it specifically requires a README file\n    'documentation_readme': 'Artefacts are clearly documented and accompanied by a README file with step-by-step instructions on how to reproduce results in the manuscript',\n    'execute': 'Scripts can be successfully executed',\n    'regenerated': 'Independent party regenerated results using the authors research artefacts',\n    'hour': 'Reproduced within approximately one hour (excluding compute time)',\n}\n\n# Evaluation for this study\n# TODO: Complete evaluate for each criteria\neval = pd.Series({\n    'archive': 0,\n    'id': 0,\n    'license': 0,\n    'complete': 0,\n    'documentation_sufficient': 0,\n    'documentation_careful': 0,\n    'relevant': 0,\n    'execute': 0,\n    'structure': 0,\n    'regenerated': 0,\n    'hour': 0,\n    'documentation_readme': 0,\n})\n\n# Get list of criteria met (True/False) overall\neval_list = list(eval)\n\n# Define function for creating the markdown formatted list of criteria met\ndef create_criteria_list(criteria_dict):\n    '''\n    Creates a string which contains a Markdown formatted list with icons to\n    indicate whether each criteria was met\n\n    Parameters:\n    -----------\n    criteria_dict : dict\n        Dictionary where keys are the criteria (variable name) and values are\n        Boolean (True/False of whether this study met the criteria)\n\n    Returns:\n    --------\n    formatted_list : string\n        Markdown formatted list\n    '''\n    callout_icon = {True: '✅',\n                    False: '❌'}\n    # Create list with...\n    formatted_list = ''.join([\n        '* ' +\n        callout_icon[eval[key]] + # Icon based on whether it met criteria\n        ' ' +\n        value + # Full text description of criteria\n        '\\n' for key, value in criteria_dict.items()])\n    return(formatted_list)\n\n# Define groups of criteria\ncriteria_share_how = ['archive', 'id', 'license']\ncriteria_share_what = ['relevant', 'complete']\ncriteria_doc_struc = ['structure', 'documentation_sufficient', 'documentation_careful', 'documentation_readme']\ncriteria_run = ['execute', 'regenerated', 'hour']\n\n# Create text section\ndisplay(Markdown(f'''\nTo assess whether the author's materials met the requirements of each badge, a list of criteria was produced. Between each badge (and between categories of badge), there is often alot of overlap in criteria.\n\nThis study met **{sum(eval_list)} of the {len(eval_list)}** unique criteria items. These were as follows:\n\nCriteria related to how artefacts are shared -\n\n{create_criteria_list({k: criteria[k] for k in criteria_share_how})}\n\nCriteria related to what artefacts are shared -\n\n{create_criteria_list({k: criteria[k] for k in criteria_share_what})}\n\nCriteria related to the structure and documentation of the artefacts -\n\n{create_criteria_list({k: criteria[k] for k in criteria_doc_struc})}\n\nCriteria related to running and reproducing results -\n\n{create_criteria_list({k: criteria[k] for k in criteria_run})}\n'''))\n\n\nTo assess whether the author’s materials met the requirements of each badge, a list of criteria was produced. Between each badge (and between categories of badge), there is often alot of overlap in criteria.\nThis study met 0 of the 12 unique criteria items. These were as follows:\nCriteria related to how artefacts are shared -\n\n❌ Stored in a permanent archive that is publicly and openly accessible\n❌ Has a persistent identifier\n❌ Includes an open license\n\nCriteria related to what artefacts are shared -\n\n❌ Arefacts are relevant to and contribute to the article’s results\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n\nCriteria related to the structure and documentation of the artefacts -\n\n❌ Artefacts are well structured/organised (e.g. to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)\n❌ Artefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)\n❌ Artefacts are carefully documented (more than sufficient - i.e. to the extent that reuse and repurposing is facilitated - e.g. changing parameters, reusing for own purpose)\n❌ Artefacts are clearly documented and accompanied by a README file with step-by-step instructions on how to reproduce results in the manuscript\n\nCriteria related to running and reproducing results -\n\n❌ Scripts can be successfully executed\n❌ Independent party regenerated results using the authors research artefacts\n❌ Reproduced within approximately one hour (excluding compute time)"
  },
  {
    "objectID": "evaluation/badges.html#badges",
    "href": "evaluation/badges.html#badges",
    "title": "Journal badges",
    "section": "Badges",
    "text": "Badges\n\n\nCode\n# Full badge names\nbadge_names = {\n    # Open objects\n    'open_niso': 'NISO \"Open Research Objects (ORO)\"',\n    'open_niso_all': 'NISO \"Open Research Objects - All (ORO-A)\"',\n    'open_acm': 'ACM \"Artifacts Available\"',\n    'open_cos': 'COS \"Open Code\"',\n    'open_ieee': 'IEEE \"Code Available\"',\n    # Object review\n    'review_acm_functional': 'ACM \"Artifacts Evaluated - Functional\"',\n    'review_acm_reusable': 'ACM \"Artifacts Evaluated - Reusable\"',\n    'review_ieee': 'IEEE \"Code Reviewed\"',\n    # Results reproduced\n    'reproduce_niso': 'NISO \"Results Reproduced (ROR-R)\"',\n    'reproduce_acm': 'ACM \"Results Reproduced\"',\n    'reproduce_ieee': 'IEEE \"Code Reproducible\"',\n    'reproduce_psy': 'Psychological Science \"Computational Reproducibility\"'\n}\n\n# Criteria required by each badge\nbadges = {\n    # Open objects\n    'open_niso': ['archive', 'id', 'license'],\n    'open_niso_all': ['archive', 'id', 'license', 'complete'],\n    'open_acm': ['archive', 'id'],\n    'open_cos': ['archive', 'id', 'license', 'complete', 'documentation_sufficient'],\n    'open_ieee': ['complete'],\n    # Object review\n    'review_acm_functional': ['documentation_sufficient', 'relevant', 'complete', 'execute'],\n    'review_acm_reusable': ['documentation_sufficient', 'documentation_careful', 'relevant', 'complete', 'execute', 'structure'],\n    'review_ieee': ['complete', 'execute'],\n    # Results reproduced\n    'reproduce_niso': ['regenerated'],\n    'reproduce_acm': ['regenerated'],\n    'reproduce_ieee': ['regenerated'],\n    'reproduce_psy': ['regenerated', 'hour', 'structure', 'documentation_readme'],\n}\n\n# Identify which badges would be awarded based on criteria\n# Get list of badges met (True/False) overall\naward = {}\nfor badge in badges:\n    award[badge] = all([eval[key] == 1 for key in badges[badge]])\naward_list = list(award.values())\n\n# Write introduction\n# Get list of badges met (True/False) by category\naward_open = [v for k,v in award.items() if k.startswith('open_')]\naward_review = [v for k,v in award.items() if k.startswith('review_')]\naward_reproduce = [v for k,v in award.items() if k.startswith('reproduce_')]\n\n# Create and display text for introduction\ndisplay(Markdown(f'''\nIn total, the original study met the criteria for **{sum(award_list)} of the {len(award_list)} badges**. This included:\n\n* **{sum(award_open)} of the {len(award_open)}** “open objects” badges\n* **{sum(award_review)} of the {len(award_review)}** “object review” badges\n* **{sum(award_reproduce)} of the {len(award_reproduce)}** “reproduced” badges\n'''))\n\n# Make function that creates collapsible callouts for each badge\ndef create_badge_callout(award_dict):\n    '''\n    Displays Markdown callouts created for each badge in the dictionary, showing\n    whether the criteria for that badge was met.\n\n    Parameters:\n    -----------\n    award_dict : dict\n        Dictionary where key is badge (as variable name), and value is Boolean\n        (whether badge is awarded)\n    '''\n    callout_appearance = {True: 'tip',\n                          False: 'warning'}\n    callout_icon = {True: '✅',\n                    False: '❌'}\n    callout_text = {True: 'Meets all criteria:',\n                    False: 'Does not meet all criteria:'}\n\n    for key, value in award_dict.items():\n        # Create Markdown list with...\n        criteria_list = ''.join([\n            '* ' +\n            callout_icon[eval[k]] + # Icon based on whether it met criteria\n            ' ' +\n            criteria[k] + # Full text description of criteria\n            '\\n' for k in badges[key]])\n        # Create the callout and display it\n        display(Markdown(f'''\n::: {{.callout-{callout_appearance[value]} appearance=\"minimal\" collapse=true}}\n\n## {callout_icon[value]} {badge_names[key]}\n\n{callout_text[value]}\n\n{criteria_list}\n:::\n'''))\n\n# Create badge functions with introductions and callouts\ndisplay(Markdown('''\n### \"Open objects\" badges\n\nThese badges relate to research artefacts being made openly available.\n'''))\ncreate_badge_callout({k: v for (k, v) in award.items() if k.startswith('open_')})\n\ndisplay(Markdown('''\n### \"Object review\" badges\n\nThese badges relate to the research artefacts being reviewed against criteria of the badge issuer.\n'''))\ncreate_badge_callout({k: v for (k, v) in award.items() if k.startswith('review_')})\n\ndisplay(Markdown('''\n### \"Reproduced\" badges\n\nThese badges relate to an independent party regenerating the reuslts of the article using the author objects.\n'''))\ncreate_badge_callout({k: v for (k, v) in award.items() if k.startswith('reproduce_')})\n\n\nIn total, the original study met the criteria for 0 of the 12 badges. This included:\n\n0 of the 5 “open objects” badges\n0 of the 3 “object review” badges\n0 of the 4 “reproduced” badges\n\n\n\n“Open objects” badges\nThese badges relate to research artefacts being made openly available.\n\n\n\n\n\n\n\n\n❌ NISO “Open Research Objects (ORO)”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Stored in a permanent archive that is publicly and openly accessible\n❌ Has a persistent identifier\n❌ Includes an open license\n\n\n\n\n\n\n\n\n\n\n\n\n❌ NISO “Open Research Objects - All (ORO-A)”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Stored in a permanent archive that is publicly and openly accessible\n❌ Has a persistent identifier\n❌ Includes an open license\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n\n\n\n\n\n\n\n\n\n\n\n\n❌ ACM “Artifacts Available”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Stored in a permanent archive that is publicly and openly accessible\n❌ Has a persistent identifier\n\n\n\n\n\n\n\n\n\n\n\n\n❌ COS “Open Code”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Stored in a permanent archive that is publicly and openly accessible\n❌ Has a persistent identifier\n❌ Includes an open license\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n❌ Artefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)\n\n\n\n\n\n\n\n\n\n\n\n\n❌ IEEE “Code Available”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n\n\n\n\n\n\n“Object review” badges\nThese badges relate to the research artefacts being reviewed against criteria of the badge issuer.\n\n\n\n\n\n\n\n\n❌ ACM “Artifacts Evaluated - Functional”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Artefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)\n❌ Arefacts are relevant to and contribute to the article’s results\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n❌ Scripts can be successfully executed\n\n\n\n\n\n\n\n\n\n\n\n\n❌ ACM “Artifacts Evaluated - Reusable”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Artefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)\n❌ Artefacts are carefully documented (more than sufficient - i.e. to the extent that reuse and repurposing is facilitated - e.g. changing parameters, reusing for own purpose)\n❌ Arefacts are relevant to and contribute to the article’s results\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n❌ Scripts can be successfully executed\n❌ Artefacts are well structured/organised (e.g. to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)\n\n\n\n\n\n\n\n\n\n\n\n\n❌ IEEE “Code Reviewed”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n❌ Scripts can be successfully executed\n\n\n\n\n\n\n“Reproduced” badges\nThese badges relate to an independent party regenerating the reuslts of the article using the author objects.\n\n\n\n\n\n\n\n\n❌ NISO “Results Reproduced (ROR-R)”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Independent party regenerated results using the authors research artefacts\n\n\n\n\n\n\n\n\n\n\n\n\n❌ ACM “Results Reproduced”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Independent party regenerated results using the authors research artefacts\n\n\n\n\n\n\n\n\n\n\n\n\n❌ IEEE “Code Reproducible”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Independent party regenerated results using the authors research artefacts\n\n\n\n\n\n\n\n\n\n\n\n\n❌ Psychological Science “Computational Reproducibility”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Independent party regenerated results using the authors research artefacts\n❌ Reproduced within approximately one hour (excluding compute time)\n❌ Artefacts are well structured/organised (e.g. to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)\n❌ Artefacts are clearly documented and accompanied by a README file with step-by-step instructions on how to reproduce results in the manuscript"
  },
  {
    "objectID": "evaluation/badges.html#sources",
    "href": "evaluation/badges.html#sources",
    "title": "Journal badges",
    "section": "Sources",
    "text": "Sources\nNational Information Standards Organisation (NISO) (NISO Reproducibility Badging and Definitions Working Group (2021))\n\n“Open Research Objects (ORO)”\n“Open Research Objects - All (ORO-A)”\n“Results Reproduced (ROR-R)”\n\nAssociation for Computing Machinery (ACM) (Association for Computing Machinery (ACM) (2020))\n\n“Artifacts Available”\n“Artifacts Evaluated - Functional”\n“Artifacts Evaluated - Resuable”\n“Results Reproduced”\n\nCenter for Open Science (COS) (Blohowiak et al. (2023))\n\n“Open Code”\n\nInstitute of Electrical and Electronics Engineers (IEEE) (Institute of Electrical and Electronics Engineers (IEEE) (n.d.))\n\n“Code Available”\n“Code Reviewed”\n“Code Reproducible”\n\nPsychological Science (Hardwicke and Vazire (2023) and Association for Psychological Science (APS) (2023))\n\n“Computational Reproducibility”"
  },
  {
    "objectID": "evaluation/scope.html",
    "href": "evaluation/scope.html",
    "title": "Scope",
    "section": "",
    "text": "This page outlines that parts of the journal article which we will attempt to reproduce.\nAs cited throughout, images on this page are sourced from Shoaib and Ramamohan (2021), which is shared under CC BY-NC-ND."
  },
  {
    "objectID": "evaluation/scope.html#within-scope",
    "href": "evaluation/scope.html#within-scope",
    "title": "Scope",
    "section": "Within scope",
    "text": "Within scope\nThere are 17 items in the scope (1 table, 9 figures, and 7 in-text results).\n\n\n\n\n\n\nTable 6\n\n\n\n\n\n\n\n\nTable 6. “Operational outcomes for each PHC configuration simulation. * Number of doctors/OPD cases/IPD cases/childbirth/ANC (patients)/inpatient beds/labour room” Shoaib and Ramamohan (2021)\n\n\nCSV version:\n\nimport pandas as pd\n\ntab6 = pd.read_csv('../original_study/tab6.csv')\ntab6\n\n\n\n\n\n\n\n\noutcome\nconfig1_mean\nconfig1_sd\nconfig2_mean\nconfig2_sd\nconfig3_mean\nconfig3_sd\nbenchmark_mean\nbenchmark_sd\n\n\n\n\n0\nDoctor utilisation\n0.268\n0.003\n0.372\n0.004\n0.354\n0.002\n1.142\n0.006\n\n\n1\nNCD Nurse utilisation\n0.865\n0.011\n0.469\n0.005\n0.468\n0.005\n1.232\n0.019\n\n\n2\nStaff nurse utilisation\n0.323\n0.008\n0.243\n0.006\n0.160\n0.001\n0.322\n0.008\n\n\n3\nPharmacist utilisation\n0.643\n0.004\n0.288\n0.003\n0.289\n0.003\n0.855\n0.005\n\n\n4\nLab utilisation\n0.559\n0.008\n0.254\n0.004\n0.239\n0.004\n0.736\n0.011\n\n\n5\nInpatient bed utilisation\n0.093\n0.004\n0.055\n0.003\n0.011\n0.001\n0.093\n0.004\n\n\n6\nLabour bed utilisation\n0.283\n0.010\n0.153\n0.009\nNaN\nNaN\n0.281\n0.012\n\n\n7\nMean length of OPD queue (number of patients)\n0.000\n0.000\n0.007\n0.001\n0.001\n0.000\n0.817\n0.027\n\n\n8\nOPD queue waiting time (minutes)\n0.009\n0.004\n0.171\n0.032\n0.034\n0.001\n6.789\n0.268\n\n\n9\nMean length of pharmacy queue (number of patie...\n0.090\n0.002\n0.010\n0.001\n0.009\n0.000\n0.150\n0.002\n\n\n10\nPharmacy queue waiting time (minutes)\n1.025\n0.021\n0.244\n0.008\n0.232\n0.006\n1.282\n0.018\n\n\n11\nMean length of Lab queue (number of patients)\n0.094\n0.003\n0.012\n0.001\n0.011\n0.000\n0.188\n0.001\n\n\n12\nLab queue waiting time (minutes)\n2.084\n0.054\n0.606\n0.023\n0.571\n0.020\n3.135\n0.005\n\n\n13\nFraction of childbirth cases referred\n0.156\n0.019\n0.088\n0.022\nNaN\nNaN\n0.157\n0.180\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2a\n\n\n\n\n\n\n\n\nFigure 2a. “Impact on doctor’s utilisation.” Shoaib and Ramamohan (2021)\n\n\n\n\n\n\n\n\n\n\n\nFigure 2b\n\n\n\n\n\n\n\n\nFigure 2b. “Impact on the NCD nurse’s utilisation.” Shoaib and Ramamohan (2021)\n\n\n\n\n\n\n\n\n\n\n\nFigure 2c\n\n\n\n\n\n\n\n\nFigure 2c. “Impact on the average waiting time (minutes) in the OPD”. Shoaib and Ramamohan (2021)\n\n\n\n\n\n\n\n\n\n\n\nFigure 2d\n\n\n\n\n\n\n\n\nFigure 2d. “Impact on the average waiting time (minutes) in the pharmacy”. Shoaib and Ramamohan (2021)\n\n\n\n\n\n\n\n\n\n\n\nFigure 3a\n\n\n\n\n\n\n\n\nFigure 3a. “Impact on the doctor’s utilisation. Two levels of outpatient consultation times (minutes) are used”. Shoaib and Ramamohan (2021)\n\n\n\n\n\n\n\n\n\n\n\nFigure 3b\n\n\n\n\n\n\n\n\nFigure 3b. “Impact on the staff nurse’s utilisation”. Shoaib and Ramamohan (2021)\n\n\n\n\n\n\n\n\n\n\n\nFigure 3c\n\n\n\n\n\n\n\n\nFigure 3c. “Impact on the inpatient bed’s utilisation”. Shoaib and Ramamohan (2021)\n\n\n\n\n\n\n\n\n\n\n\nFigure 3d\n\n\n\n\n\n\n\n\nFigure 3d. “Impact on the proportion of childbirth cases referred elsewhere”. Shoaib and Ramamohan (2021)\n\n\n\n\n\n\n\n\n\n\n\nFigure 4\n\n\n\n\n\n\n\n\nFigure 4. “Effect of including additional labour beds on proportion of childbirth patients referred elsewhere”. Shoaib and Ramamohan (2021)\n\n\n\n\n\n\n\n\n\n\n\nIn-text result 1\n\n\n\n\n\nFrom section 4.3: “We also note that waiting times for outpatient-related resources (laboratory, OPD consultation, etc. - not depicted in Figures 3a – 3d) increase marginally because the associated resources are also required by inpatient/childbirth/ANC cases, which increase in number in the above scenarios”\nInterpretation:\n\nRun sensitivity analysis as in Figures 3a-d, but look at outcomes relating to laboratory and outpatient consulation\nResult: marginal increase\n\n\n\n\n\n\n\n\n\n\nIn-text result 2\n\n\n\n\n\nFrom section 4.3.1: “To address this, we experimented with letting the staff nurse (whose utilisation is approximately 32%) take over the administrative work. This led to a 12% drop in the utilisation level, which implied that the doctor’s utilisation still exceeded 100%. Implementing this measure resulted in increasing the staff nurse utilisation to nearly 40%.”\nInterpretation:\n\nAverage patient load of 170 per day\nAverage consultation time of 5 min per patient\nChange doctor to have no administrative work, and assign all to staff nurse\nResults: doctor utilisation 103%\n\n103% is because the next result is 1% below, and as there is a 12% drop from fig 2a, still over 100%, and nurse utilisation at 40%\n\n\n\n\n\n\n\n\n\nIn-text result 3\n\n\n\n\n\nFrom section 4.3.1: “then considered a situation wherein the staff nurses require minimal intervention in childbirth cases. We assumed that in 50% of childbirth cases, staff nurses require no intervention by the doctor; require only one- third of the typical amount of intervention in 30% of cases, and require full intervention in the remaining 20% of cases. This led to a decrease of the doctor’s utilisation to 101% (a further decrease of approximately 1%), and an increase in the nurse’s utilisation to 40%.”\nInterpretation:\n\nAverage patient load of 170 per day\nAverage consultation time of 5 min per patient\nChange doctors from always attending childbirth cases when free to 50% not attending, 30% attending but for one-third of normal time, 20% attending for normal time\nResult: Doctor utilisation 101% and nurse utilisation 40%\n\n\n\n\n\n\n\n\n\n\nIn-text result 4\n\n\n\n\n\nFrom section 4.3.1: “investigated the effect of stationing an additional doctor in the PHC. This yielded an average utilisation of well below 100% for each doctor.”\nInterpretation:\n\nAverage patient load of 170 per day\nAverage consultation time of 5 min per patient\nAdd a doctor\nResult: each doctor has utilisation “well below 100%”\n\n\n\n\n\n\n\n\n\n\nIn-text result 5\n\n\n\n\n\nFrom section 4.3.2: “We also observe that if the number of beds is reduced to four from six, the utilisation level is observed to be approximately thirty-three percent even under higher demand conditions (two inpatient and childbirth cases/day).”\nInterpretation:\n\nReduce from six to four inpatient beds\nConditions un-specified (assume standard, and also high demand (2 inpatient and childbirth cases per day))\nResult: Approximately 33% utilisation\n\n\n\n\n\n\n\n\n\n\nIn-text result 6\n\n\n\n\n\nFrom section 4.3.3: “When the administrative work alone is assigned to the staff nurse the average utilisation of the NCD nurse decreases to 100%”\nInterpretation:\n\nOutpatient interarrival time 3 minutes\nNo administrative work for NCD nurse, only assigned to staff nurse\nResult: NCD nurse utilisation 100%\n\n\n\n\n\n\n\n\n\n\nIn-text result 7\n\n\n\n\n\nFrom section 4.3.3: “Further, in addition to the administrative work when the staff nurse assisted for NCD checks (for 10% cases) the utilisation of NCD nurse dropped to 71%.”\nInterpretation:\n\nOutpatient interarrival time 3 minutes\nPotentially combined with change in administrative work\nAssigned staff nurse for 10% of NCD cases\nResult: NCD nurse utilisation 71%"
  },
  {
    "objectID": "evaluation/scope.html#outside-scope",
    "href": "evaluation/scope.html#outside-scope",
    "title": "Scope",
    "section": "Outside scope",
    "text": "Outside scope\nThese are tables and figures from the main body of the text which were considered to be outside the scope of this reproduction.\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\n\n\n\nFigure 1. “Patient flow in the archetypal PHC”. Shoaib and Ramamohan (2021)\n\n\n\n\n\n\n\n\n\n\n\nTable 1\n\n\n\n\n\n\n\n\nTable 1. “Data summary of staffing level, patient load, and other facilities at PHCs”. Shoaib and Ramamohan (2021)\n\n\n\n\n\n\n\n\n\n\n\nTable 2\n\n\n\n\n\n\n\n\nTable 2. “Service time data summary for key PHC resources”. Shoaib and Ramamohan (2021)\n\n\n\n\n\n\n\n\n\n\n\nTable 3\n\n\n\n\n\n\n\n\nTable 3. “PHC configurations. 1: Note: the nurses work in shifts – that is, each nurse works alone in an eight-hour shift. NA = not applicable. All configurations have 6 inpatient beds and 1 childbirth room (with a single bed).” Shoaib and Ramamohan (2021)\n\n\n\n\n\n\n\n\n\n\n\nTable 4\n\n\n\n\n\n\n\n\nTable 4. “Facility independent input parameters”. Shoaib and Ramamohan (2021)\n\n\n\n\n\n\n\n\n\n\n\nTable 5\n\n\n\n\n\n\n\n\nTable 5. “Internal validation outcomes for doctor’s utilisation”. Shoaib and Ramamohan (2021)"
  },
  {
    "objectID": "evaluation/reproduction_report.html",
    "href": "evaluation/reproduction_report.html",
    "title": "Summary report",
    "section": "",
    "text": "Please note: This is a template page and has not yet been completed"
  },
  {
    "objectID": "evaluation/reproduction_report.html#study",
    "href": "evaluation/reproduction_report.html#study",
    "title": "Summary report",
    "section": "Study",
    "text": "Study\n\n[Authors]. [Title]. [Journal] [Volume], [Edition] ([Year]). &lt;[URL]&gt;.\n\n[Paragraph summarising model]"
  },
  {
    "objectID": "evaluation/reproduction_report.html#computational-reproducibility",
    "href": "evaluation/reproduction_report.html#computational-reproducibility",
    "title": "Summary report",
    "section": "Computational reproducibility",
    "text": "Computational reproducibility\nSuccessfully reproduced X figures (X%) within scope in Xh Xm (X%).\nRequired troubleshooting:\n\n[List of required changes to code]\n\n\nItem XItem YFigure 4\n\n\n[One sentence description of item X]\n[Display side-by-side] \n\n\n[Set-up as for Item X]\n\n\n[Set-up as for Item X]"
  },
  {
    "objectID": "evaluation/reproduction_report.html#evaluation-against-guidelines",
    "href": "evaluation/reproduction_report.html#evaluation-against-guidelines",
    "title": "Summary report",
    "section": "Evaluation against guidelines",
    "text": "Evaluation against guidelines\n\n\n                                                \n\n\nContext: The original study repository was evaluated against criteria from journal badges relating to how open and reproducible the model is and against guidance for sharing artefacts from the STARS framework. The original study article and supplementary materials (excluding code) were evaluated against reporting guidelines for DES models: STRESS-DES, and guidelines adapted from ISPOR-SDM."
  },
  {
    "objectID": "evaluation/artefacts.html",
    "href": "evaluation/artefacts.html",
    "title": "STARS framework",
    "section": "",
    "text": "Please note: This is a template page and has not yet been completed\nThis page evaluates the extent to which the original study meets the recommendations from the STARS framework for the sharing of code and associated materials from discrete-event simulation models (Monks, Harper, and Mustafee (2024)).\nOf the 8 essential STARS components:\n\n\nX were met fully (✅)\nX was met partially (🟡)\nX was not met (❌)\n\nOf the 5 optional STARS components:\n\n\nX was met fully (✅)\nX were not met (❌)\n\n\n\n\n\n\n\n\n\n\n\nComponent\nDescription\nMet by study?\nEvidence/location\n\n\n\n\nEssential components\n\n\n\n\n\nOpen license\nFree and open-source software (FOSS) license (e.g. MIT, GNU Public License (GPL))\n\n\n\n\nDependency management\nSpecify software libraries, version numbers and sources (e.g. dependency management tools like virtualenv, conda, poetry)\n\n\n\n\nFOSS model\nCoded in FOSS language (e.g. R, Julia, Python)\n\n\n\n\nMinimum documentation\nMinimal instructions (e.g. in README) that overview (a) what model does, (b) how to install and run model to obtain results, and (c) how to vary parameters to run new experiments\n\n\n\n\nORCID\nORCID for each study author\n\n\n\n\nCitation information\nInstructions on how to cite the research artefact (e.g. CITATION.cff file)\n\n\n\n\nRemote code repository\nCode available in a remote code repository (e.g. GitHub, GitLab, BitBucket)\n\n\n\n\nOpen science archive\nCode stored in an open science archive with FORCE11 compliant citation and guaranteed persistance of digital artefacts (e.g. Figshare, Zenodo, the Open Science Framework (OSF), and the Computational Modeling in the Social and Ecological Sciences Network (CoMSES Net))\n\n\n\n\nOptional components\n\n\n\n\n\nEnhanced documentation\nOpen and high quality documentation on how the model is implemented and works (e.g. via notebooks and markdown files, brought together using software like Quarto and Jupyter Book). Suggested content includes:• Plain english summary of project and model• Clarifying license• Citation instructions• Contribution instructions• Model installation instructions• Structured code walk through of model• Documentation of modelling cycle using TRACE• Annotated simulation reporting guidelines• Clear description of model validation including its intended purpose\n\n\n\n\nDocumentation hosting\nHost documentation (e.g. with GitHub pages, GitLab pages, BitBucket Cloud, Quarto Pub)\n\n\n\n\nOnline coding environment\nProvide an online environment where users can run and change code (e.g. BinderHub, Google Colaboratory, Deepnote)\n\n\n\n\nModel interface\nProvide web application interface to the model so it is accessible to less technical simulation users\n\n\n\n\nWeb app hosting\nHost web app online (e.g. Streamlit Community Cloud, ShinyApps hosting)\n\n\n\n\n\n\n\n\n\nReferences\n\nMonks, Thomas, Alison Harper, and Navonil Mustafee. 2024. “Towards Sharing Tools and Artefacts for Reusable Simulations in Healthcare.” Journal of Simulation 0 (0): 1–20. https://doi.org/10.1080/17477778.2024.2347882."
  },
  {
    "objectID": "evaluation/reproduction_success.html",
    "href": "evaluation/reproduction_success.html",
    "title": "Reproduction success",
    "section": "",
    "text": "Please note: This is a template page and has not yet been completed\nOf the X items in the scope, X% (X out of X) were considered to be successfully reproduced."
  },
  {
    "objectID": "evaluation/reproduction_success.html#figure-x",
    "href": "evaluation/reproduction_success.html#figure-x",
    "title": "Reproduction success",
    "section": "Figure X",
    "text": "Figure X\nOriginal figure:\n\nReproduction:"
  },
  {
    "objectID": "logbook/posts/2024_06_21/index.html",
    "href": "logbook/posts/2024_06_21/index.html",
    "title": "Day 2",
    "section": "",
    "text": "Note\n\n\n\nBuilt environment and got Table 6 config 1 results. Total time used: 8h 51m (22%)"
  },
  {
    "objectID": "logbook/posts/2024_06_21/index.html#archive-scope-on-zenodo",
    "href": "logbook/posts/2024_06_21/index.html#archive-scope-on-zenodo",
    "title": "Day 2",
    "section": "10.02-10.16: Archive scope on Zenodo",
    "text": "10.02-10.16: Archive scope on Zenodo\nArchiving repository on Zenodo, now that have made consensus decision on scope following:\n\nDiscussion with Tom yesterday.\nEmails with Alison this morning, who also had a look over paper and our planned scope, and confirmed that she felt it looked complete.\n\nBefore doing so, created entry in CHANGELOG.md and updated CITATION.cff to include myself, Tom and Alison, and to amend the version and title."
  },
  {
    "objectID": "logbook/posts/2024_06_21/index.html#look-over-code",
    "href": "logbook/posts/2024_06_21/index.html#look-over-code",
    "title": "Day 2",
    "section": "10.23-10.30 : Look over code",
    "text": "10.23-10.30 : Look over code\n\nAll code in PHC.py.\nSalabim.\nModel created using classes.\nFunction main() defines parameters (e.g. number of doctors) and runs model.\nNo random seed.\nSaves results to .xlsx with lots of stats (can spot lots from Table 6). Also outputs the input parameters used.\nCan’t spot code for defined scenarios or figures, so anticipating will need to create for self."
  },
  {
    "objectID": "logbook/posts/2024_06_21/index.html#timings-below-set-up-environment",
    "href": "logbook/posts/2024_06_21/index.html#timings-below-set-up-environment",
    "title": "Day 2",
    "section": "(Timings below): Set up environment",
    "text": "(Timings below): Set up environment\nTimings for this section (provided as list rather than in header as often paused for time spent solving environment):\n\n10.31-10.47\n11.00-11.01\n11.03-11.04\n11.12-11.35\n\nNo environment file provided. Can’t spot Python or Salabim version in the paper, nor in README from prior commit. Therefore:\n\nDependencies from PHC.py\n\nDidn’t include random as should be in base\n\nModel code commit to GitHub on 14th March 2021. Paper first published online with simulation 18th July 2021, and latest arXiv version from 21st June 2021.\nHence, looked for package versions with dates on or prior to the earlier 14th March 2021.\n\nhttps://pypi.org/project/matplotlib/#history\nhttps://pypi.org/project/numpy/#history\nhttps://devguide.python.org/versions/\nhttps://pypi.org/project/salabim/#history\nhttps://pypi.org/project/statistics/#history\nhttps://pypi.org/project/XlsxWriter/#history\n\n\nname: shoaib2022\nchannels:\n  - defaults\ndependencies:\n  - matplotlib=3.3.4\n  - numpy=1.20.1\n  - pip=21.0.1\n  - python=3.9\n  - statistics=1.0.3.5\n  - xlsxwriter=1.3.7\n  - xlwt=1.3.0\n  - pip:\n    - salabim==21.0.2\nSpent along time solving environment and looking for incompatable packages (which excluded from timing above). Had lots of conflicts:\nUnsatisfiableError: The following specifications were found to be incompatible with each other:\n\nOutput in format: Requested package -&gt; Available versions\n\nPackage libuuid conflicts for:\nxlwt=1.3.0 -&gt; python[version='&gt;=3.11,&lt;3.12.0a0'] -&gt; libuuid[version='&gt;=1.0.3,&lt;2.0a0|&gt;=1.41.5,&lt;2.0a0']\nstatistics=1.0.3.5 -&gt; python[version='&gt;=3.10,&lt;3.11.0a0'] -&gt; libuuid[version='&gt;=1.0.3,&lt;2.0a0|&gt;=1.41.5,&lt;2.0a0']\nxlsxwriter=1.3.7 -&gt; python -&gt; libuuid[version='&gt;=1.0.3,&lt;2.0a0|&gt;=1.41.5,&lt;2.0a0']\n\nPackage certifi conflicts for:\npip=21.0.1 -&gt; setuptools -&gt; certifi[version='&gt;=2016.09|&gt;=2016.9.26']\nmatplotlib=3.3.4 -&gt; matplotlib-base[version='&gt;=3.3.4,&lt;3.3.5.0a0'] -&gt; certifi[version='&gt;=2020.06.20']\n\nPackage _libgcc_mutex conflicts for:\nnumpy=1.20.1 -&gt; libgcc-ng[version='&gt;=7.3.0'] -&gt; _libgcc_mutex[version='*|0.1',build=main]\npython=3.9 -&gt; libgcc-ng[version='&gt;=11.2.0'] -&gt; _libgcc_mutex[version='*|0.1',build=main]\n\nPackage pip conflicts for:\nnumpy=1.20.1 -&gt; python[version='&gt;=3.9,&lt;3.10.0a0'] -&gt; pip\nxlwt=1.3.0 -&gt; python[version='&gt;=3.11,&lt;3.12.0a0'] -&gt; pip\nmatplotlib=3.3.4 -&gt; python[version='&gt;=3.7,&lt;3.8.0a0'] -&gt; pip\nxlsxwriter=1.3.7 -&gt; python -&gt; pip\npip=21.0.1\npython=3.9 -&gt; pip\n\nPackage wheel conflicts for:\npython=3.9 -&gt; pip -&gt; wheel\npip=21.0.1 -&gt; wheel\n\nPackage ca-certificates conflicts for:\nxlwt=1.3.0 -&gt; python[version='&gt;=2.7,&lt;2.8.0a0'] -&gt; ca-certificates\npython=3.9 -&gt; openssl[version='&gt;=3.0.13,&lt;4.0a0'] -&gt; ca-certificates\nstatistics=1.0.3.5 -&gt; python[version='&lt;3'] -&gt; ca-certificates\nxlsxwriter=1.3.7 -&gt; python -&gt; ca-certificates\n\nPackage setuptools conflicts for:\npython=3.9 -&gt; pip -&gt; setuptools\nmatplotlib=3.3.4 -&gt; matplotlib-base[version='&gt;=3.3.4,&lt;3.3.5.0a0'] -&gt; setuptools\npip=21.0.1 -&gt; setuptools\n\nPackage numpy conflicts for:\nmatplotlib=3.3.4 -&gt; matplotlib-base[version='&gt;=3.3.4,&lt;3.3.5.0a0'] -&gt; numpy[version='&gt;=1.16.6,&lt;2.0a0']\nnumpy=1.20.1The following specifications were found to be incompatible with your system:\n\n  - feature:/linux-64::__glibc==2.35=0\n  - feature:|@/linux-64::__glibc==2.35=0\n  - numpy=1.20.1 -&gt; libgcc-ng[version='&gt;=7.3.0'] -&gt; __glibc[version='&gt;=2.17']\n  - python=3.9 -&gt; libgcc-ng[version='&gt;=11.2.0'] -&gt; __glibc[version='&gt;=2.17']\n\nYour installed version is: 2.35\nInstead of going package by package, tried out a simpler approach of changing to only specify the Python version and none of the individual packages. Still found lots of conflicts:\nPackage expat conflicts for:\nnumpy -&gt; python[version='&gt;=3.12,&lt;3.13.0a0'] -&gt; expat[version='&gt;=2.5.0,&lt;3.0a0|&gt;=2.6.2,&lt;3.0a0']\nxlsxwriter -&gt; python[version='&gt;=3.12,&lt;3.13.0a0'] -&gt; expat[version='&gt;=2.5.0,&lt;3.0a0|&gt;=2.6.2,&lt;3.0a0']\nmatplotlib -&gt; python[version='&gt;=3.12,&lt;3.13.0a0'] -&gt; expat[version='&gt;=2.5.0,&lt;3.0a0|&gt;=2.6.2,&lt;3.0a0']\npip -&gt; python[version='&gt;=3.12,&lt;3.13.0a0'] -&gt; expat[version='&gt;=2.5.0,&lt;3.0a0|&gt;=2.6.2,&lt;3.0a0']\n\nPackage numpy conflicts for:\nnumpy\nmatplotlib -&gt; matplotlib-base[version='&gt;=3.8.4,&lt;3.8.5.0a0'] -&gt; numpy[version='&gt;=1.15.4,&lt;2.0a0|&gt;=1.16.6,&lt;2.0a0|&gt;=1.20|&gt;=1.21.5,&lt;2.0a0|&gt;=1.21.6,&lt;2.0a0|&gt;=1.23.5,&lt;2.0a0|&gt;=1.26.4,&lt;2.0a0|&gt;=1.26.0,&lt;2.0a0|&gt;=1.22.3,&lt;2.0a0|&gt;=1.19.2,&lt;2.0a0|&gt;=1.21.2,&lt;2.0a0']\nmatplotlib -&gt; numpy[version='&gt;=1.14.6,&lt;2.0a0']\n\nPackage _libgcc_mutex conflicts for:\nmatplotlib -&gt; libgcc-ng[version='&gt;=7.3.0'] -&gt; _libgcc_mutex[version='*|0.1',build=main]\nnumpy -&gt; libgcc-ng[version='&gt;=11.2.0'] -&gt; _libgcc_mutex[version='*|0.1',build=main]\npython=3.9 -&gt; libgcc-ng[version='&gt;=11.2.0'] -&gt; _libgcc_mutex[version='*|0.1',build=main]\n\nPackage certifi conflicts for:\nmatplotlib -&gt; tornado -&gt; certifi[version='&gt;=2016.09|&gt;=2016.9.26|&gt;=2020.06.20']\npip -&gt; setuptools -&gt; certifi[version='&gt;=2016.09|&gt;=2016.9.26']\n\nPackage python conflicts for:\npip -&gt; python[version='&gt;=2.7,&lt;2.8.0a0|&gt;=3.10,&lt;3.11.0a0|&gt;=3.11,&lt;3.12.0a0|&gt;=3.9,&lt;3.10.0a0|&gt;=3.12,&lt;3.13.0a0|&gt;=3.8,&lt;3.9.0a0|&gt;=3.7,&lt;3.8.0a0|&gt;=3.6,&lt;3.7.0a0|&gt;=3.5,&lt;3.6.0a0']\npython=3.9\npip -&gt; wheel -&gt; python\nmatplotlib -&gt; cycler[version='&gt;=0.10'] -&gt; python[version='&gt;=3|&gt;=3.6']\nxlsxwriter -&gt; python[version='&gt;=2.7,&lt;2.8.0a0|&gt;=3.10,&lt;3.11.0a0|&gt;=3.12,&lt;3.13.0a0|&gt;=3.9,&lt;3.10.0a0|&gt;=3.8,&lt;3.9.0a0|&gt;=3.11,&lt;3.12.0a0|&gt;=3.4|&gt;=3.6,&lt;3.7.0a0|&gt;=3.7,&lt;3.8.0a0|&gt;=3.5,&lt;3.6.0a0']\nxlwt -&gt; python[version='&gt;=2.7,&lt;2.8.0a0|&gt;=3.10,&lt;3.11.0a0|&gt;=3.11,&lt;3.12.0a0|&gt;=3.9,&lt;3.10.0a0|&gt;=3.8,&lt;3.9.0a0|&gt;=3.7,&lt;3.8.0a0|&gt;=3.6,&lt;3.7.0a0|&gt;=3.5,&lt;3.6.0a0']\nstatistics -&gt; docutils[version='&gt;=0.3'] -&gt; python[version='&gt;=3.11,&lt;3.12.0a0|&gt;=3.12,&lt;3.13.0a0|&gt;=3.7,&lt;3.8.0a0|&gt;=3.9,&lt;3.10.0a0|&gt;=3.8,&lt;3.9.0a0|&gt;=3.6,&lt;3.7.0a0|&gt;=3.5,&lt;3.6.0a0']\nmatplotlib -&gt; python[version='&gt;=2.7,&lt;2.8.0a0|&gt;=3.10,&lt;3.11.0a0|&gt;=3.11,&lt;3.12.0a0|&gt;=3.9,&lt;3.10.0a0|&gt;=3.12,&lt;3.13.0a0|&gt;=3.8,&lt;3.9.0a0|&gt;=3.7,&lt;3.8.0a0|&gt;=3.6,&lt;3.7.0a0|&gt;=3.5,&lt;3.6.0a0']\nnumpy -&gt; python[version='&gt;=2.7,&lt;2.8.0a0|&gt;=3.10,&lt;3.11.0a0|&gt;=3.11,&lt;3.12.0a0|&gt;=3.12,&lt;3.13.0a0|&gt;=3.9,&lt;3.10.0a0|&gt;=3.8,&lt;3.9.0a0|&gt;=3.7,&lt;3.8.0a0|&gt;=3.6,&lt;3.7.0a0|&gt;=3.5,&lt;3.6.0a0']\nstatistics -&gt; python[version='&lt;3|&gt;=3.10,&lt;3.11.0a0|&gt;=2.7,&lt;2.8.0a0']\n\nPackage bzip2 conflicts for:\nxlsxwriter -&gt; python[version='&gt;=3.12,&lt;3.13.0a0'] -&gt; bzip2[version='&gt;=1.0.8,&lt;2.0a0']\nmatplotlib -&gt; python[version='&gt;=3.11,&lt;3.12.0a0'] -&gt; bzip2[version='&gt;=1.0.8,&lt;2.0a0']\nnumpy -&gt; python[version='&gt;=3.10,&lt;3.11.0a0'] -&gt; bzip2[version='&gt;=1.0.8,&lt;2.0a0']\nxlwt -&gt; python[version='&gt;=3.11,&lt;3.12.0a0'] -&gt; bzip2[version='&gt;=1.0.8,&lt;2.0a0']\nstatistics -&gt; python[version='&gt;=3.10,&lt;3.11.0a0'] -&gt; bzip2[version='&gt;=1.0.8,&lt;2.0a0']\npip -&gt; python[version='&gt;=3.11,&lt;3.12.0a0'] -&gt; bzip2[version='&gt;=1.0.8,&lt;2.0a0']\n\nPackage setuptools conflicts for:\npython=3.9 -&gt; pip -&gt; setuptools\npip -&gt; setuptools\nmatplotlib -&gt; setuptools\n\nPackage wheel conflicts for:\npip -&gt; wheel\npython=3.9 -&gt; pip -&gt; wheelThe following specifications were found to be incompatible with your system:\n\n  - feature:/linux-64::__glibc==2.35=0\n  - matplotlib -&gt; libgcc-ng[version='&gt;=7.3.0'] -&gt; __glibc[version='&gt;=2.17']\n  - numpy -&gt; libgcc-ng[version='&gt;=11.2.0'] -&gt; __glibc[version='&gt;=2.17']\n  - python=3.9 -&gt; libgcc-ng[version='&gt;=11.2.0'] -&gt; __glibc[version='&gt;=2.17']\n\nYour installed version is: 2.35\nBased on this stack overflow post, decided to instead try using mamba.\nconda install -n base conda-forge::mamba\nBut then read that was not recommended so tried -\ncurl -L -O \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\"\nBut that wasn’t working so deleted and tried these instructions -\nwget https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh\n\nbash Mambaforge-Linux-x86_64.sh\n\nyes\n\nyes\n\n# Closed terminal then reopened terminal\nThen, tried creating environment:\nmamba env create -f environment.yml\nThis returned a more understandable message:\nLibMambaUnsatisfiableError: Encountered problems while solving:\n  - package statistics-1.0.3.5-py27_1 requires python &gt;=2.7,&lt;2.8.0a0, but none of the providers can be installed\n\nCould not solve for environment specs\nThe following packages are incompatible\n├─ python 3.9**  is requested and can be installed;\n└─ statistics is not installable because there are no viable options\n   ├─ statistics 1.0.3.5 would require\n   │  └─ python [2.7* |&gt;=2.7,&lt;2.8.0a0 ], which conflicts with any installable versions previously reported;\n   ├─ statistics 1.0.3.5 would require\n   │  └─ python &gt;=3.10,&lt;3.11.0a0 , which conflicts with any installable versions previously reported;\n   └─ statistics 1.0.3.5 would require\n      └─ python &lt;3 , which conflicts with any installable versions previously reported.\nAppears from this message (and supported versions listed on pypi) that would need to switch to python 2.7. Environment then successfully installed, and update .yml to show versions it used.\nname: shoaib2022\nchannels:\n  - defaults\ndependencies:\n  - matplotlib=2.2.3\n  - numpy=1.16.6\n  - pip=19.3.1\n  - python=2.7\n  - statistics=1.0.3.5\n  - xlsxwriter=3.0.1\n  - xlwt=1.3.0\n  - pip:\n    - salabim==20.0.4\nAt a glance, all are lower than those I’d previously specified, except xlsxwriter, which is 3.0.1 (10 Aug 2021). As it would not be possible for them to have used this version, I set that to 1.3.7 and rebuilt environment.\nThis built quickly and with no issue."
  },
  {
    "objectID": "logbook/posts/2024_06_21/index.html#running-script-and-returning-to-environment",
    "href": "logbook/posts/2024_06_21/index.html#running-script-and-returning-to-environment",
    "title": "Day 2",
    "section": "11.51-11.57, 12.03-12.37: Running script and returning to environment",
    "text": "11.51-11.57, 12.03-12.37: Running script and returning to environment\nCopied PHC.py into reproduction/ and ran file with environment active.\nImportError: No module named pathlib. Installed latest version of pathlib (which is from 2014) into environment.\nThen error:\nTraceback (most recent call last):\n  File \"/home/amy/Documents/stars/stars-reproduce-shoaib-2022/reproduction/PHC.py\", line 1, in &lt;module&gt;\n    import salabim as sim\n  File \"/home/amy/mambaforge/envs/shoaib2022/lib/python2.7/site-packages/salabim/__init__.py\", line 1, in &lt;module&gt;\n    from .salabim import *\n  File \"/home/amy/mambaforge/envs/shoaib2022/lib/python2.7/site-packages/salabim/salabim.py\", line 9451, in &lt;module&gt;\n    class AnimateCombined(collections.UserList):\nAttributeError: 'module' object has no attribute 'UserList'\nWanted to just explore basic salabim example first, to check environment is working, so made notebook that just imports salabim. Running required installation of ipykernel in environment. Excluded installation time for this from timings above. Then ran import salabim as sim, but this returned the same error as before just upon import.\nCurrent salabim documentation lists a few different imports that might be required. Went to old documentation on their GitHub, to the 20.0.4 branch then PDF with documentation (which is 20.0.3, but likewise if you go to 20.0.5 branch): https://github.com/salabim/salabim/blob/20%2C0%2C4/salabim.pdf. Then ran:\npip install Pillow\nWhich didn’t have much impact. Error message seems to relate to collections not having UserList. Collections is a built-in module in base python. Tried to just import collections (which was fine), then run collections.UserList which returns same error.\nLooking at documentation for Python 2.7.18, collections does not yet have UserList, but it does from 3.0.\nHave realised mistake - that statistics on conda/PyPi is an import to allow it to work with 2.7, but actually, statistics is a built-in python module that was introduced in Python 3.4.\nAs such, deleted environment and removed statistics from the requirements, and just set requirement of Python 3.9 (as tried before) and built using mamba.\nEnvironment prior:\nname: shoaib2022\nchannels:\n  - defaults\ndependencies:\n  - ipykernel=4.10.0\n  - matplotlib=2.2.3\n  - numpy=1.16.6\n  - pathlib=1.0.1\n  - pip=19.3.1\n  - python=2.7\n  - statistics=1.0.3.5\n  - xlsxwriter=1.3.7\n  - xlwt=1.3.0\n  - pip:\n    - salabim==20.0.4\nEnvironment tried now:\nname: shoaib2022\nchannels:\n  - defaults\ndependencies:\n  - ipykernel\n  - matplotlib\n  - numpy\n  - pathlib\n  - pip\n  - python=3.9\n  - xlsxwriter\n  - xlwt\n  - pip:\n    - salabim\nRun:\nconda deactivate\nconda remove -n shoaib2022 --all\nmamba env create -f environment.yml\nconda activate shoaib2022\nThis quickly installed, and updated environment file with the versions it used:\nname: shoaib2022\nchannels:\n  - defaults\ndependencies:\n  - ipykernel=6.28.0\n  - matplotlib=3.8.4\n  - numpy=1.26.4\n  - pathlib=1.0.1\n  - pip=24.0\n  - python=3.9.19\n  - xlsxwriter=3.1.1\n  - xlwt=1.3.0\n  - pip:\n    - salabim==24.0.6\nCan see that several of these are more recent that would have been possible for the paper. But trying import of salabim now works. Decided to try running the script with this environment, just to see if it can work.\nModuleNotFoundError: No module named 'greenlet'\nCan see this was suggested in the salabim documentation. Add greenlet to environment and remade environment with mamba env update -f environment.yml. This add greenlet==3.0.3. Then re-run PHC.py. Got:\nTraceback (most recent call last):\n  File \"/home/amy/Documents/stars/stars-reproduce-shoaib-2022/reproduction/PHC.py\", line 1300, in &lt;module&gt;\n    main()\n  File \"/home/amy/Documents/stars/stars-reproduce-shoaib-2022/reproduction/PHC.py\", line 932, in main\n    Main(name='')\n  File \"/home/amy/mambaforge/envs/shoaib2022/lib/python3.9/site-packages/salabim/salabim.py\", line 7131, in __init__\n    raise ValueError(\nValueError: process may not be a generator (contain yield statements.)\nMaybe this a non yieldless model. In that case:\n- add sim.yieldless(False) or\n- remove all yields or\n- run salabim_unyield.py"
  },
  {
    "objectID": "logbook/posts/2024_06_21/index.html#continued-and-got-config1-table6-results-confirmed-match",
    "href": "logbook/posts/2024_06_21/index.html#continued-and-got-config1-table6-results-confirmed-match",
    "title": "Day 2",
    "section": "13.17-15.07: Continued and got config1 table6 results (confirmed match)",
    "text": "13.17-15.07: Continued and got config1 table6 results (confirmed match)\nSuspicious my error could be because I’m used versions that are more recent than I know possible. Hence, delete environment and this time rebuild as specified at start but without statistics, but with the new ones I know I need, with versions based on their release history. Exception was ipykernel, as that was something I’ve added to run notebooks, and not something the original study required.\nname: shoaib2022\nchannels:\n  - defaults\ndependencies:\n  - ipykernel\n  - matplotlib=3.3.4\n  - numpy=1.20.1\n  - pathlib=1.0.1\n  - pip=21.0.1\n  - python=3.9.19\n  - xlsxwriter=1.3.7\n  - xlwt=1.3.0\n  - pip:\n    - greenlet==1.0.0\n    - salabim==21.0.2\nThis built fine! So probably would’ve worked to begin with without statistics. Then ran PHC.py, and it started running fine, outputting No of replications done 0, No of replications done 1…\nEnsure is set up with correct parameters. Configuration 1 is (from Table 3 and 6):\n\n2 doctors: doc_cap = 2\n4 nurses: staff_nurse_cap = 3, NCD_nurse_cap = 1\n130 OPD cases, so OPD inter-arrival time 4: OPD_iat = 4\n0.5 IPD cases, so IPD inter-arrival time 2880: IPD_iat = 2880\n1 childbirth, so childbirth inter-arrival time 1440: delivery_iat = 1440\n1 ANC (patients), so ANC inter-arrival time 1440: ANC_iat = 1440\n6 inpatient beds: bed = sim.Resource(\"Bed\", capacity=6)\n1 labour room: delivery_bed = sim.Resource(\"Del bed\", capacity = 1)\n100 replications: replication = 10\n365 days: days = 365\nWarm-up 180 days: warm_up = 180*24*60\n\nExcept for number of replications, all match up to configuration 1.\nProduced Outputs.xlsx in main folder, which moved manually to reproduction/, and copied to logbook folder to display below. This ran ten replications, with results in each column.\n\nimport xlrd\nimport pandas as pd\n\nmodel_path = 'Outputs.xls'\n\nbook = xlrd.open_workbook(model_path)\nresult = pd.read_excel(book, header=None, index_col=0)\nresult\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOPD patients\n32836.000000\n33066.000000\n33023.000000\n32870.000000\n33240.000000\n33232.000000\n33216.000000\n33368.000000\n33314.000000\n33171.000000\n\n\nIPD patients\n174.000000\n166.000000\n171.000000\n177.000000\n198.000000\n194.000000\n206.000000\n178.000000\n198.000000\n178.000000\n\n\nANC patients\n368.000000\n362.000000\n386.000000\n380.000000\n388.000000\n381.000000\n372.000000\n370.000000\n350.000000\n355.000000\n\n\nDel patients\n384.000000\n367.000000\n369.000000\n361.000000\n309.000000\n360.000000\n359.000000\n397.000000\n385.000000\n339.000000\n\n\nOPD Q wt\n0.006038\n0.008066\n0.006059\n0.006793\n0.005244\n0.010225\n0.007012\n0.016915\n0.008484\n0.018205\n\n\nPharmacy Q wt\n1.047611\n1.019909\n1.011980\n1.016690\n1.006467\n1.032219\n1.020334\n1.017687\n1.017410\n1.003815\n\n\nLab Q wt\n2.063080\n2.096727\n2.121108\n1.958464\n2.096112\n2.160190\n2.039157\n2.069498\n2.135470\n2.139755\n\n\ndoc occ\n0.269761\n0.271455\n0.265695\n0.271491\n0.266211\n0.269985\n0.269385\n0.274394\n0.270916\n0.264823\n\n\nLab patient list\n34553.000000\n68973.000000\n103851.000000\n137618.000000\n172163.000000\n206714.000000\n241073.000000\n275273.000000\n309924.000000\n344492.000000\n\n\nOPD q len\n0.005855\n0.009359\n0.004993\n0.007724\n0.005061\n0.011423\n0.005998\n0.010305\n0.010064\n0.017429\n\n\nipd occ\n0.100000\n0.100000\n0.100000\n0.100000\n0.090000\n0.100000\n0.090000\n0.100000\n0.100000\n0.100000\n\n\nopd q len\n0.000531\n0.000713\n0.000535\n0.000598\n0.000462\n0.000909\n0.000619\n0.001494\n0.000751\n0.001609\n\n\npharmacy q len\n0.091809\n0.089833\n0.089091\n0.089266\n0.088519\n0.091496\n0.089756\n0.089564\n0.089736\n0.088452\n\n\nlab q len\n0.093966\n0.095058\n0.097672\n0.087332\n0.095604\n0.098494\n0.092430\n0.093381\n0.097421\n0.097366\n\n\nNCD occ\n0.856243\n0.876655\n0.868920\n0.862815\n0.875444\n0.864627\n0.873573\n0.882904\n0.885179\n0.851488\n\n\nlab occ\n0.559366\n0.552778\n0.566939\n0.550767\n0.558711\n0.559475\n0.554049\n0.557318\n0.562513\n0.553164\n\n\npharm occ\n0.637989\n0.643297\n0.639525\n0.638504\n0.644518\n0.642726\n0.645787\n0.647810\n0.647879\n0.641500\n\n\nstaff nurse occ\n0.328762\n0.322683\n0.321956\n0.321020\n0.305951\n0.322970\n0.323056\n0.335735\n0.331135\n0.312820\n\n\ndel occ\n0.280000\n0.290000\n0.300000\n0.290000\n0.260000\n0.290000\n0.280000\n0.300000\n0.300000\n0.280000\n\n\ndel referred\n58.000000\n53.000000\n56.000000\n54.000000\n44.000000\n55.000000\n55.000000\n62.000000\n72.000000\n47.000000\n\n\nNCD occ\n0.856243\n0.876655\n0.868920\n0.862815\n0.875444\n0.864627\n0.873573\n0.882904\n0.885179\n0.851488\n\n\nipd bed occ\n0.101028\n0.091502\n0.097690\n0.092269\n0.082897\n0.094390\n0.091500\n0.098772\n0.092360\n0.090019\n\n\n\n\n\n\n\nAdd xlrd and pandas to environment (quarto and reproduction) so can import the .xls files produced and process them.\nProcessed this in reproduce.ipynb so can match up results to Table 6 (as use different label names), and calculate proportion of childbirth referred.\nConfirmed that values all matched up with only apx. 1% difference at most, which is great!"
  },
  {
    "objectID": "logbook/posts/2024_06_21/index.html#second-results-spreadsheet",
    "href": "logbook/posts/2024_06_21/index.html#second-results-spreadsheet",
    "title": "Day 2",
    "section": "15.23-16.17: Second results spreadsheet",
    "text": "15.23-16.17: Second results spreadsheet\nThere is REPLICATION = xlsxwriter.Workbook(\"Config_3(2).xlsx\") with results that I didn’t get. Tried uncommenting REPLICATION.close() and reran PHC.py.\nAlso, changed save location of the output files, so they go into reproduction/outputs/ rather than main folder, by modifying PHC.py.\nIn reproduction.ipynb, compared results from that to the processed Outputs.xls. To import .xlsx file using pd.read_excel, had to add openpyxl to environment.\n\ncompare = pd.read_csv('t6_mean_compare.csv')\ncompare\n\n\n\n\n\n\n\n\nt6_outcome\nsimple_outcome\nfull_outcome\nt6_result\nsimple_result\nfull_result\n\n\n\n\n0\nDoctor utilisation\ndoc occ\nDoctor Occupancy\n0.268\n0.269412\n0.269358\n\n\n1\nNCD Nurse utilisation\nNCD occ\nNCD Nurse Occupancy\n0.865\n0.869785\n0.860000\n\n\n2\nStaff nurse utilisation\nstaff nurse occ\nStaff nurse Occupancy\n0.323\n0.322609\n0.330000\n\n\n3\nPharmacist utilisation\npharm occ\nPharmacist Occupancy\n0.643\n0.642954\n0.642419\n\n\n4\nLab utilisation\nlab occ\nLab Occupancy\n0.559\n0.557508\n0.680000\n\n\n5\nInpatient bed utilisation\nipd bed occ\nBed occupancy\n0.093\n0.093243\n0.090000\n\n\n6\nLabour bed utilisation\ndel occ\nNaN\n0.283\n0.287000\nNaN\n\n\n7\nMean length of OPD queue (number of patients)\nOPD q len\nMean length of OPD queue\n0.000\n0.008821\n0.000900\n\n\n8\nOPD queue waiting time (minutes)\nOPD Q wt\nOPD queue waiting time\n0.009\n0.009304\n0.009700\n\n\n9\nMean length of pharmacy queue (number of patie...\npharmacy q len\nMean length of pharmacy queue\n0.090\n0.089752\n0.090000\n\n\n10\nPharmacy queue waiting time (minutes)\nPharmacy Q wt\nPharmacy queue waiting time\n1.025\n1.019412\n1.030000\n\n\n11\nMean length of Lab queue (number of patients)\nlab q len\nMean length of Lab queue\n0.094\n0.094872\n0.100000\n\n\n12\nLab queue waiting time (minutes)\nLab Q wt\nLab queue waiting time\n2.084\n2.087956\n2.080000\n\n\n13\nFraction of childbirth cases referred\nprop_del_referred\nNaN\n0.156\n0.153168\nNaN\n\n\n\n\n\n\n\nThis had similar results but observations:\n\nDifferent labels again\nAlso does not have fraction of childbirth cases referred\nCan’t spot labour bed utilisation in the larger results table\n\nThe results are not an exact match but all are likely due to rounding differences. As the outputs one was processed additionally using spreadsheet with replication results, feel its better to use the full results spreadsheet they create, as that works with the raw results (and not potentially rounded results in the spreadsheet).\nMatch:\n\ndoctor utilisation\npharmacist utilisation\n\nDon’t match:\n\nncd nurse utilisation (rounding?)\nstaff nurse utilisation (rounding?)\nlab utilisation (rounding?)\nbed occupancy (rounding?)\nmean OPD queue length (rounding as simple results using replication spreadsheet which might have rounding)\nOPD queue waiting times (rounding?)\nmean pharmacy queue length (rounding?)\npharacy queue waiting tim (rounding?)\nlab queue waiting time (rounding?)\n\nHowever, that doesn’t have the standard deviation for all the results included - and its missing labour bed utilisation and fraction of childbirth cases. Also, the full result is potentially more rounded than the reported, and as it was commented out in the .py file originally, that lends me to suspect that results could likely be based on the replication spreadsheet results.\nDecision: Use replication spreadsheet results."
  },
  {
    "objectID": "logbook/posts/2024_06_21/index.html#setting-parameter-values-from-notebook",
    "href": "logbook/posts/2024_06_21/index.html#setting-parameter-values-from-notebook",
    "title": "Day 2",
    "section": "16.22-16.48: Setting parameter values from notebook",
    "text": "16.22-16.48: Setting parameter values from notebook\nIn order to run the different scenarios without needing to change the PHC.py itself each time, worked to modify the function main() so that the parameters provided to that function are inputs.\nThen ran the model from reproduce.ipynb."
  },
  {
    "objectID": "logbook/posts/2024_06_21/index.html#timings",
    "href": "logbook/posts/2024_06_21/index.html#timings",
    "title": "Day 2",
    "section": "Timings",
    "text": "Timings\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 239\n\n# Times from today\ntimes = [\n    ('10.02', '10.16'),\n    ('10.23', '10.30'),\n    ('10.31', '10.47'),\n    ('11.00', '11.01'),\n    ('11.03', '11.04'),\n    ('11.12', '11.35'),\n    ('11.51', '11.57'),\n    ('12.03', '12.37'),\n    ('13.17', '15.07'),\n    ('15.23', '16.17'),\n    ('16.22', '16.48')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 292m, or 4h 52m\nTotal used to date: 531m, or 8h 51m\nTime remaining: 1869m, or 31h 9m\nUsed 22.1% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_06_25/index.html",
    "href": "logbook/posts/2024_06_25/index.html",
    "title": "Day 4",
    "section": "",
    "text": "Note\n\n\n\nTable 6 100 rep, and created Figure 2A-D. Total time used: TBCh TBCm (TBC%)"
  },
  {
    "objectID": "logbook/posts/2024_06_25/index.html#run-100-replications-for-table-6",
    "href": "logbook/posts/2024_06_25/index.html#run-100-replications-for-table-6",
    "title": "Day 4",
    "section": "6.55-6.57: Run 100 replications for Table 6",
    "text": "6.55-6.57: Run 100 replications for Table 6\nStart running with 100 replications. Taking too long (ran through 259 replications in 110 minutes), so only got through 2 full configurations before needing to shut it down to go to work."
  },
  {
    "objectID": "logbook/posts/2024_06_25/index.html#used-parallel-processing-when-running-the-replications",
    "href": "logbook/posts/2024_06_25/index.html#used-parallel-processing-when-running-the-replications",
    "title": "Day 4",
    "section": "9.26-9.50, 10.50-10.51: Used parallel processing when running the replications",
    "text": "9.26-9.50, 10.50-10.51: Used parallel processing when running the replications\nSet up parallel processing in reproduce_tab6.ipynb to run the 4 sets of 100 replications. It took 61 minutes to run (excluded from timing). Once complete, I looked over the table and was satisified that the mean and SD values were close enough to the original, and considered it now completely successfully reproduced (at timestamp: 10.51). I disregarded some high percent change that were simply due to comparison of numbers very close to zero, and the difference was actually very small.\nEmailed to Tom and Alison to share second opinion.\nTiming for when Table 6 is completed (i.e. as of 10.51):\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 829\n\n# Times from today\ntimes = [\n    ('6.55', '6.57'),\n    ('9.26', '9.50'),\n    ('10.50', '10.51')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 27m, or 0h 27m\nTotal used to date: 856m, or 14h 16m\nTime remaining: 1544m, or 25h 44m\nUsed 35.7% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_06_25/index.html#saved-output-from-processed-replications-and-confirmation-from-tom-and-alison",
    "href": "logbook/posts/2024_06_25/index.html#saved-output-from-processed-replications-and-confirmation-from-tom-and-alison",
    "title": "Day 4",
    "section": "11.04-11.17: Saved output from processed replications, and confirmation from Tom and Alison",
    "text": "11.04-11.17: Saved output from processed replications, and confirmation from Tom and Alison\nEdited notebook so model is not re-run each time (due to long run time), and then saved the processed results to a csv file.\nBoth Tom and Alison responded to confirm they were happy this was reproduced.\nRe-ran % change calculations with rounded values. As before, observe that we are sometimes comparing very small numbers - so e.g. mean of 0.011 v.s. 0.012 comes out as 9% change. It also sometimes finds large differences for small SD values (e.g. 1360% change), when actually, I’m not too concerned by the difference in the grand scheme of things."
  },
  {
    "objectID": "logbook/posts/2024_06_25/index.html#create-figure-2b",
    "href": "logbook/posts/2024_06_25/index.html#create-figure-2b",
    "title": "Day 4",
    "section": "11.30-11.50: Create Figure 2B",
    "text": "11.30-11.50: Create Figure 2B\nImported and processed data from the arrival number replications, and produced Figure 2B. Happy that this is succesfully reproduced at timepoint 11.50. In order to declare this reproduced, I feel I do not require to run the same number of replications (100), as understand this would have no meaningful impact on result being plot (mean), and am happy with consistency to original at 10 replications.\n\n# Minutes used prior to this figure\nused_to_date = 856\n\n# Times from today\ntimes = [\n    ('11.04', '11.17'),\n    ('11.30', '11.50')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 33m, or 0h 33m\nTotal used to date: 889m, or 14h 49m\nTime remaining: 1511m, or 25h 11m\nUsed 37.0% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_06_25/index.html#create-figure-2c",
    "href": "logbook/posts/2024_06_25/index.html#create-figure-2c",
    "title": "Day 4",
    "section": "11.51-12.08, 12.13-12.17: Create Figure 2C",
    "text": "11.51-12.08, 12.13-12.17: Create Figure 2C\nUsing OPD Q wt (which matched up to OPD queue waiting time for Table 6), results look rather different. They only go up to 0.01, whilst in Figure 2C, results go from under 1 up to just under 7. That is closer to the waiting time in the benchmark model, implying these results are obtained with those doctor numbers.\n\n\n\nIncorrect reproduction of Fig2c\n\n\nWhen run with the serv5 appointment times, the results match up with the paper. Feel this has been succesfully reproduced at time 12.17.\n\n\n\nSuccessful reproduction of Fig2c\n\n\nObservation: Reproduced figure, but not from how I understood it had been set up from the text (unless that was my misunderstanding - which is quite possible!).\n\n# Minutes used prior to this figure\nused_to_date = 889\n\n# Times from today\ntimes = [\n    ('11.51', '12.08'),\n    ('12.13', '12.17')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 21m, or 0h 21m\nTotal used to date: 910m, or 15h 10m\nTime remaining: 1490m, or 24h 50m\nUsed 37.9% of 40 hours max\n\n\nEmailed to Tom and Alison - and Tom confirmed that Fig2B and 2C are succesful.\n\n\n\n\n\n\nReflections from Tom from these reproductions\n\n\n\nIncluding code to (re)generate figures\nIncluding tick marks on axes so that people can easily read across or judge whether a bar goes above a Y value or not"
  },
  {
    "objectID": "logbook/posts/2024_06_25/index.html#add-grid-lines-to-figures",
    "href": "logbook/posts/2024_06_25/index.html#add-grid-lines-to-figures",
    "title": "Day 4",
    "section": "13.20-13.26: Add grid lines to figures",
    "text": "13.20-13.26: Add grid lines to figures\nAdd horizontal grid lines to Figures 2B and 2C, to improve readability."
  },
  {
    "objectID": "logbook/posts/2024_06_25/index.html#working-on-figure-2a",
    "href": "logbook/posts/2024_06_25/index.html#working-on-figure-2a",
    "title": "Day 4",
    "section": "13.29-13.44, 13.47-14.04, 14.13-14.19, 14.24-14.41: Working on Figure 2A",
    "text": "13.29-13.44, 13.47-14.04, 14.13-14.19, 14.24-14.41: Working on Figure 2A\nThe text and figures do not provide the boundary used when sampling the consultation time. From previous implementations we know:\n\nMean 0.87 uses boundaries 0.3/0.5\nMean 5 uses boundary 2\n\nHowever, we do not know for mean 2.5. We might reasonably estimate that it would be around 1, but this is a guess and not substantiated by evidence.\nRan all nine combinations set up with parallel processing but only 10 replications, run time 3m 22s.\nCreated Figure 2A, and - despite guessing for the 2.5 (0.5) boundaries - I feel the bar heights are sufficiently similar to mark this as successfully reproduced at 14.41.\n\n# Minutes used prior to this figure\nused_to_date = 910\n\n# Times from today\ntimes = [\n    ('13.20', '13.26'),\n    ('13.29', '13.44'),\n    ('13.47', '14.04'),\n    ('14.13', '14.19'),\n    ('14.24', '14.41')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 61m, or 1h 1m\nTotal used to date: 971m, or 16h 11m\nTime remaining: 1429m, or 23h 49m\nUsed 40.5% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_06_25/index.html#creating-figure-2d",
    "href": "logbook/posts/2024_06_25/index.html#creating-figure-2d",
    "title": "Day 4",
    "section": "14.44-14.54: Creating Figure 2D",
    "text": "14.44-14.54: Creating Figure 2D\nProduced Figure 2D using same data and similar code to Figure 2A.\nAgain, feel sufficiently similar to mark as successfully reproduced at 14.54.\n\n# Minutes used prior to this figure\nused_to_date = 971\n\n# Times from today\ntimes = [\n    ('14.44', '14.54')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 10m, or 0h 10m\nTotal used to date: 981m, or 16h 21m\nTime remaining: 1419m, or 23h 39m\nUsed 40.9% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_06_25/index.html#creating-figure-3a",
    "href": "logbook/posts/2024_06_25/index.html#creating-figure-3a",
    "title": "Day 4",
    "section": "15.10-15.21, 15.24-15.34: Creating Figure 3A",
    "text": "15.10-15.21, 15.24-15.34: Creating Figure 3A\nBased scenarios on the labels for Figure 3. These were varying:\n\nNumber of inpatient/childbirth/ANC cases per day:\n\n1 = IAT 1440 (e.g. like IPD cases for config1)\n2 = IAT 720 (as 2880 is 0.5 per day and 1440 is 1 per day)\n\nAverage service time for outpatients:\n\n0.87 (0.21) (same as config1)\n2.5 (0.5) (as in figure 2)\n\n\nSet up and ran 10 replications with parallel processing. Took 3 minutes.\nAdapted code created for Figure 2A/D to make Figure 3A. Successfully reproduced at 15.34.\n\n# Minutes used prior to this figure\nused_to_date = 981\n\n# Times from today\ntimes = [\n    ('15.10', '15.21'),\n    ('15.24', '15.34')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 21m, or 0h 21m\nTotal used to date: 1002m, or 16h 42m\nTime remaining: 1398m, or 23h 18m\nUsed 41.8% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_06_25/index.html#x-creating-figure-3b",
    "href": "logbook/posts/2024_06_25/index.html#x-creating-figure-3b",
    "title": "Day 4",
    "section": "15.45-X: Creating Figure 3B",
    "text": "15.45-X: Creating Figure 3B"
  },
  {
    "objectID": "logbook/posts/2024_06_25/index.html#timings",
    "href": "logbook/posts/2024_06_25/index.html#timings",
    "title": "Day 4",
    "section": "Timings",
    "text": "Timings\n\n# Minutes used prior to today\nused_to_date = 829\n\n# Times from today\ntimes = [\n    ('6.55', '6.57'),\n    ('9.26', '9.50'),\n    ('10.50', '10.51'),\n    ('11.04', '11.17'),\n    ('11.30', '11.50'),\n    ('11.51', '12.08'),\n    ('12.13', '12.17'),\n    ('13.20', '13.26'),\n    ('13.29', '13.44'),\n    ('13.47', '14.04'),\n    ('14.13', '14.19'),\n    ('14.24', '14.41'),\n    ('14.44', '14.54'),\n    ('15.10', '15.21'),\n    ('15.24', '15.34')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 173m, or 2h 53m\nTotal used to date: 1002m, or 16h 42m\nTime remaining: 1398m, or 23h 18m\nUsed 41.8% of 40 hours max"
  },
  {
    "objectID": "logbook/logbook.html",
    "href": "logbook/logbook.html",
    "title": "Logbook",
    "section": "",
    "text": "These diary entries record daily progress in reproduction of the study, providing a transparent and detailed record of work.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDay 4\n\n\n\n\n\n\nreproduce\n\n\n\n\n\n\n\n\n\nJun 25, 2024\n\n\nAmy Heather\n\n\n\n\n\n\n\n\n\n\n\n\nDay 3\n\n\n\n\n\n\nreproduce\n\n\n\n\n\n\n\n\n\nJun 24, 2024\n\n\nAmy Heather\n\n\n\n\n\n\n\n\n\n\n\n\nDay 2\n\n\n\n\n\n\nscope\n\n\nread\n\n\nreproduce\n\n\n\n\n\n\n\n\n\nJun 21, 2024\n\n\nAmy Heather\n\n\n\n\n\n\n\n\n\n\n\n\nDay 1\n\n\n\n\n\n\nsetup\n\n\nread\n\n\nscope\n\n\n\n\n\n\n\n\n\nJun 20, 2024\n\n\nAmy Heather\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Reproducing Shoaib and Ramamohan 2022",
    "section": "",
    "text": "This book captures the reproduction of:\n\nShoaib M, Ramamohan V. Simulation modeling and analysis of primary health center operations. SIMULATION 98(3):183-208. (2022). https://doi.org/10.1177/00375497211030931.\n\nUse the navigation bar above to view:\n\nOriginal study - the original study article and associated artefacts.\nReproduction - code and documentation from reproduction of the model.\nEvaluation - describes model reproduction success and compares original study against guidelines for sharing research, criteria for journal reproducibility guidelines, and article reporting guidelines.\nLogbook - chronological entries detailing reproduction work.\nSummary - summary of the computational reproducibility assessment."
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Reproducing Shoaib and Ramamohan 2022",
    "section": "",
    "text": "This book captures the reproduction of:\n\nShoaib M, Ramamohan V. Simulation modeling and analysis of primary health center operations. SIMULATION 98(3):183-208. (2022). https://doi.org/10.1177/00375497211030931.\n\nUse the navigation bar above to view:\n\nOriginal study - the original study article and associated artefacts.\nReproduction - code and documentation from reproduction of the model.\nEvaluation - describes model reproduction success and compares original study against guidelines for sharing research, criteria for journal reproducibility guidelines, and article reporting guidelines.\nLogbook - chronological entries detailing reproduction work.\nSummary - summary of the computational reproducibility assessment."
  },
  {
    "objectID": "index.html#project-team",
    "href": "index.html#project-team",
    "title": "Reproducing Shoaib and Ramamohan 2022",
    "section": "Project team",
    "text": "Project team\n\n\nConducting this reproduction:\n\nAmy Heather \n\nProviding support during the reproduction:\n\nThomas Monks \nAlison Harper \n\nOther members of the team on STARS:\n\nNavonil Mustafee \nAndrew Mayne"
  },
  {
    "objectID": "index.html#protocol",
    "href": "index.html#protocol",
    "title": "Reproducing Shoaib and Ramamohan 2022",
    "section": "Protocol",
    "text": "Protocol\nThe protocol for this work is summarised in the diagram below and archived on Zenodo:\n\nHeather, A., Monks, T., Harper, A., Mustafee, N., & Mayne, A. (2024). Protocol for assessing the computational reproducibility of discrete-event simulation models on STARS. Zenodo. https://doi.org/10.5281/zenodo.12179846.\n\n\n\n\nWorkflow for computational reproducibility assessment"
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "Reproducing Shoaib and Ramamohan 2022",
    "section": "Citation",
    "text": "Citation\nAPA: Heather A., Monks T., Harper A. (2024). STARS: Computational reproducibility of Shoaib and Ramamohan 2022 (version 0.1.0). URL: https://github.com/pythonhealthdatascience/stars-reproduce-shoaib-2022\nSee CITATION.cff and citation_bibtex.bib for alternative formats."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Reproducing Shoaib and Ramamohan 2022",
    "section": "License",
    "text": "License\nSee License page."
  },
  {
    "objectID": "quarto_site/study_publication.html",
    "href": "quarto_site/study_publication.html",
    "title": "Publication",
    "section": "",
    "text": "View at: https://github.com/pythonhealthdatascience/stars-reproduce-shoaib-2022/tree/main/original_study/PHC--main\nCode from: https://github.com/shoaibiocl/PHC-"
  },
  {
    "objectID": "quarto_site/study_publication.html#code-and-data",
    "href": "quarto_site/study_publication.html#code-and-data",
    "title": "Publication",
    "section": "",
    "text": "View at: https://github.com/pythonhealthdatascience/stars-reproduce-shoaib-2022/tree/main/original_study/PHC--main\nCode from: https://github.com/shoaibiocl/PHC-"
  },
  {
    "objectID": "quarto_site/study_publication.html#journal-article",
    "href": "quarto_site/study_publication.html#journal-article",
    "title": "Publication",
    "section": "Journal article",
    "text": "Journal article\nArticle published with SIMULATION:\n\nDOI: https://doi.org/10.1177/00375497211030931\nReference: Shoaib and Ramamohan (2022) (citation from 2022 as first published online in 2021 but journal publication was March 2022 Volume 98 Issue 3)\n\nInstead, uploaded article from ArXiv (shared under CC BY-NC-ND):\n\nDOI: https://doi.org/10.48550/arXiv.2104.12492\nReference: Shoaib and Ramamohan (2021)"
  },
  {
    "objectID": "reproduction/reproduce_tab6.html",
    "href": "reproduction/reproduce_tab6.html",
    "title": "Reproducing Table 6",
    "section": "",
    "text": "This notebook currently imports results from a run of PHC.py and maps them to Table 6.\nTable 6 results are from Shoaib M, Ramamohan V. Simulation modeling and analysis of primary health center operations. SIMULATION 98(3):183-208. (2022). https://doi.org/10.1177/00375497211030931.\nRun time: 61 minutes. Will need to uncomment the timer sections and section to run model if you wish to fully rerun. These are currently commented so the notebook can otherwise be used for processing the results."
  },
  {
    "objectID": "reproduction/reproduce_tab6.html#set-up",
    "href": "reproduction/reproduce_tab6.html#set-up",
    "title": "Reproducing Table 6",
    "section": "Set up",
    "text": "Set up\n\n# To run model\nimport PHC\nimport numpy as np\n\n# To import and process results\nimport pandas as pd\nimport xlrd\nimport os\n\n# To speed up run time\nfrom multiprocessing import Pool\n\n# Additional package to record runtime of this notebook\n# import time\n# start = time.time()\n\n\ntable6_path = '../original_study/tab6.csv'\nfinal_results = 'outputs/tab6.csv'"
  },
  {
    "objectID": "reproduction/reproduce_tab6.html#run-model",
    "href": "reproduction/reproduce_tab6.html#run-model",
    "title": "Reproducing Table 6",
    "section": "Run model",
    "text": "Run model\nSet parameters for each configuration based on Table 3.\n\n# For all: days 365, warm up 180, 6 inpatient beds, 1 delivery\n# bed, 3 staff nurse, 1 NCD nurse. These are default parameters in the model,\n# and below, have just specified the parameters that changed between\n# configurations\n\nt6_c1_param = {\n    'doc_cap': 2,\n    'OPD_iat': 4,\n    'IPD_iat': 2880,\n    'delivery_iat': 1440,\n    'ANC_iat': 1440,\n    'rep_file': 't6_c1.xls',\n    'replication': 100\n}\n\nt6_c2_param = {\n    'doc_cap': 1,\n    'OPD_iat': 9,\n    'IPD_iat': 2880,\n    'delivery_iat': 2880,\n    'ANC_iat': 2880,\n    'rep_file': 't6_c2.xls',\n    'replication': 100\n}\n\nt6_c3_param = {\n    'doc_cap': 1,\n    'OPD_iat': 9,\n    'IPD_iat': 2880,\n    'any_delivery': False,\n    'any_ANC': False,\n    'rep_file': 't6_c3.xls',\n    'replication': 100\n}\n\nt6_c4_param = {\n    'doc_cap': 2,\n    'OPD_iat': 3,\n    'mean': 5,\n    'sd': 1,\n    'consult_boundary_1': 2,\n    'consult_boundary_2': 2,\n    'IPD_iat': 2880,\n    'delivery_iat': 1440,\n    'ANC_iat': 1440,\n    'rep_file': 't6_c4.xls',\n    'replication': 100\n}\n\n\n# Create list of parameter dictionaries\nconfig = [t6_c1_param, t6_c2_param, t6_c3_param, t6_c4_param]\n\n# Append 's_' to all items\nfor i, d in enumerate(config):\n    config[i] = {f's_{k}': v for k, v in d.items()}\n\nRun model for each configuration using parallel processing.\nNote: Commented out due to long run time.\n\n# Wrapper function to allow input of dictionary with pool\ndef wrapper(d):\n    return PHC.main(**d)\n\n# Create a process pool that uses all CPUs\n# with Pool(4) as pool:\n#     # Run PHC.main() using each of inputs from config\n#     pool.map(wrapper, config)"
  },
  {
    "objectID": "reproduction/reproduce_tab6.html#import-and-process-replication-results",
    "href": "reproduction/reproduce_tab6.html#import-and-process-replication-results",
    "title": "Reproducing Table 6",
    "section": "Import and process replication results",
    "text": "Import and process replication results\n\n# Make dictionary with labels from table 6, and corresponding names from model output\nt6_labels = {\n  'doc occ': 'Doctor utilisation',\n  'NCD occ': 'NCD Nurse utilisation',\n  'staff nurse occ': 'Staff nurse utilisation',\n  'pharm occ': 'Pharmacist utilisation',\n  'lab occ': 'Lab utilisation',\n  'ipd bed occ': 'Inpatient bed utilisation',\n  'del occ': 'Labour bed utilisation',  # \"Del\" stands for delivery\n  'opd q len': 'Mean length of OPD queue (number of patients)',\n  'OPD Q wt': 'OPD queue waiting time (minutes)',\n  'pharmacy q len': 'Mean length of pharmacy queue (number of patients)',\n  'Pharmacy Q wt': 'Pharmacy queue waiting time (minutes)',\n  'lab q len': 'Mean length of Lab queue (number of patients)',\n  'Lab Q wt': 'Lab queue waiting time (minutes)',\n  'prop_del_referred': 'Fraction of childbirth cases referred'\n}\n\n\n# List of files to loop through\nfiles = ['t6_c1', 't6_c2', 't6_c3', 't6_c4']\n\n# Empty list to store results\nresult_list = []\n\nfor f in files:\n    # Import .xls and convert to pandas dataframe\n    book = xlrd.open_workbook(os.path.join('outputs', f'{f}.xls'))\n    result = pd.read_excel(book, header=None, index_col=0)\n\n    # Add proportion of childbirth cases referred\n    result.loc['prop_del_referred'] = (\n        result.loc['del referred'] / result.loc['Del patients'])\n\n    # Find mean and standard deviation from the replication\n    # Save as dataframe, dropping the duplicate rows (NCD occ twice)\n    res = pd.DataFrame({\n        f'model_{f}_mean': result.mean(axis=1),\n        f'model_{f}_sd': result.std(axis=1)\n    }).drop_duplicates()\n\n    # Save to list\n    result_list.append(res)\n\n\n# Combine into single dataframe\nsummary = (pd.concat(result_list, axis=1)\n           .reset_index()\n           .rename(columns= {0: 'model_outcome'}))\n\n# Add labels to model results\nsummary['t6_outcome'] = summary['model_outcome'].map(t6_labels)\n\nsummary\n\n\n\n\n\n\n\n\nmodel_outcome\nmodel_t6_c1_mean\nmodel_t6_c1_sd\nmodel_t6_c2_mean\nmodel_t6_c2_sd\nmodel_t6_c3_mean\nmodel_t6_c3_sd\nmodel_t6_c4_mean\nmodel_t6_c4_sd\nt6_outcome\n\n\n\n\n0\nOPD patients\n3.312637e+04\n1.785897e+02\n14890.180000\n110.461052\n14857.250000\n109.384816\n4.405896e+04\n2.118088e+02\nNaN\n\n\n1\nIPD patients\n1.819400e+02\n1.219026e+01\n181.990000\n13.949762\n183.540000\n14.546630\n1.843800e+02\n1.455382e+01\nNaN\n\n\n2\nANC patients\n3.643800e+02\n1.464377e+01\n211.900000\n11.898986\n0.000000\n0.000000\n3.676700e+02\n1.572494e+01\nNaN\n\n\n3\nDel patients\n3.654500e+02\n1.906574e+01\n181.470000\n14.669046\nNaN\nNaN\n3.664800e+02\n2.039978e+01\nNaN\n\n\n4\nOPD Q wt\n8.811218e-03\n3.391605e-03\n0.182605\n0.029487\n0.034597\n0.001101\n6.968764e+00\n2.516115e-01\nOPD queue waiting time (minutes)\n\n\n5\nPharmacy Q wt\n1.025055e+00\n2.226311e-02\n0.244612\n0.008553\n0.231061\n0.006068\n1.284367e+00\n1.971490e-02\nPharmacy queue waiting time (minutes)\n\n\n6\nLab Q wt\n2.076878e+00\n5.626489e-02\n0.604793\n0.022624\n0.569570\n0.018696\n3.152544e+00\n7.267482e-02\nLab queue waiting time (minutes)\n\n\n7\ndoc occ\n2.686463e-01\n2.152930e-03\n0.372444\n0.003851\n0.353664\n0.002500\n1.143672e+00\n5.670042e-03\nDoctor utilisation\n\n\n8\nLab patient list\n1.747950e+06\n1.003715e+06\n780873.910000\n449025.249681\n782899.560000\n450041.784075\n2.313950e+06\n1.329765e+06\nNaN\n\n\n9\nOPD q len\n8.397417e-03\n4.244432e-03\n0.177137\n0.036704\n0.034150\n0.001157\n6.842035e+00\n2.987361e-01\nNaN\n\n\n10\nipd occ\n9.680000e-02\n4.898979e-03\n0.059200\n0.003674\n0.012500\n0.004352\n9.620000e-02\n5.276209e-03\nNaN\n\n\n11\nopd q len\n7.778837e-04\n3.002725e-04\n0.007237\n0.001175\n0.001365\n0.000047\n8.172893e-01\n3.179206e-02\nMean length of OPD queue (number of patients)\n\n\n12\npharmacy q len\n9.021882e-02\n2.221468e-03\n0.009664\n0.000364\n0.009116\n0.000268\n1.502997e-01\n2.681526e-03\nMean length of pharmacy queue (number of patie...\n\n\n13\nlab q len\n9.470264e-02\n2.732832e-03\n0.012461\n0.000534\n0.011257\n0.000411\n1.889212e-01\n5.530848e-03\nMean length of Lab queue (number of patients)\n\n\n14\nNCD occ\n8.661105e-01\n9.540874e-03\n0.468966\n0.005556\n0.467952\n0.004912\n1.231325e+00\n1.873619e-02\nNCD Nurse utilisation\n\n\n15\nlab occ\n5.590886e-01\n7.612054e-03\n0.253639\n0.004737\n0.239393\n0.004237\n7.337385e-01\n1.190204e-02\nLab utilisation\n\n\n16\npharm occ\n6.429655e-01\n3.610861e-03\n0.288813\n0.002505\n0.288200\n0.002420\n8.554212e-01\n4.398680e-03\nPharmacist utilisation\n\n\n17\nstaff nurse occ\n3.228974e-01\n7.589217e-03\n0.243063\n0.005772\n0.160844\n0.001431\n3.239551e-01\n7.993417e-03\nStaff nurse utilisation\n\n\n18\ndel occ\n2.826000e-01\n1.177397e-02\n0.152300\n0.010717\nNaN\nNaN\n2.815000e-01\n1.282162e-02\nLabour bed utilisation\n\n\n19\ndel referred\n5.640000e+01\n7.697566e+00\n15.720000\n3.814062\nNaN\nNaN\n5.901000e+01\n8.879092e+00\nNaN\n\n\n20\nipd bed occ\n9.370063e-02\n4.367457e-03\n0.055842\n0.003817\n0.011606\n0.000960\n9.386653e-02\n4.481425e-03\nInpatient bed utilisation\n\n\n21\nprop_del_referred\n1.540155e-01\n1.645332e-02\n0.086324\n0.018355\nNaN\nNaN\n1.605759e-01\n1.899443e-02\nFraction of childbirth cases referred"
  },
  {
    "objectID": "reproduction/reproduce_tab6.html#import-table-6-results-and-compare-against-run-results",
    "href": "reproduction/reproduce_tab6.html#import-table-6-results-and-compare-against-run-results",
    "title": "Reproducing Table 6",
    "section": "Import table 6 results and compare against run results",
    "text": "Import table 6 results and compare against run results\n\n# Import table 6\nt6 = pd.read_csv(table6_path).rename(columns={'outcome': 't6_outcome'})\nt6\n\n\n\n\n\n\n\n\nt6_outcome\nconfig1_mean\nconfig1_sd\nconfig2_mean\nconfig2_sd\nconfig3_mean\nconfig3_sd\nbenchmark_mean\nbenchmark_sd\n\n\n\n\n0\nDoctor utilisation\n0.268\n0.003\n0.372\n0.004\n0.354\n0.002\n1.142\n0.006\n\n\n1\nNCD Nurse utilisation\n0.865\n0.011\n0.469\n0.005\n0.468\n0.005\n1.232\n0.019\n\n\n2\nStaff nurse utilisation\n0.323\n0.008\n0.243\n0.006\n0.160\n0.001\n0.322\n0.008\n\n\n3\nPharmacist utilisation\n0.643\n0.004\n0.288\n0.003\n0.289\n0.003\n0.855\n0.005\n\n\n4\nLab utilisation\n0.559\n0.008\n0.254\n0.004\n0.239\n0.004\n0.736\n0.011\n\n\n5\nInpatient bed utilisation\n0.093\n0.004\n0.055\n0.003\n0.011\n0.001\n0.093\n0.004\n\n\n6\nLabour bed utilisation\n0.283\n0.010\n0.153\n0.009\nNaN\nNaN\n0.281\n0.012\n\n\n7\nMean length of OPD queue (number of patients)\n0.000\n0.000\n0.007\n0.001\n0.001\n0.000\n0.817\n0.027\n\n\n8\nOPD queue waiting time (minutes)\n0.009\n0.004\n0.171\n0.032\n0.034\n0.001\n6.789\n0.268\n\n\n9\nMean length of pharmacy queue (number of patie...\n0.090\n0.002\n0.010\n0.001\n0.009\n0.000\n0.150\n0.002\n\n\n10\nPharmacy queue waiting time (minutes)\n1.025\n0.021\n0.244\n0.008\n0.232\n0.006\n1.282\n0.018\n\n\n11\nMean length of Lab queue (number of patients)\n0.094\n0.003\n0.012\n0.001\n0.011\n0.000\n0.188\n0.001\n\n\n12\nLab queue waiting time (minutes)\n2.084\n0.054\n0.606\n0.023\n0.571\n0.020\n3.135\n0.005\n\n\n13\nFraction of childbirth cases referred\n0.156\n0.019\n0.088\n0.022\nNaN\nNaN\n0.157\n0.180\n\n\n\n\n\n\n\n\n# Round to 3dp (as in table) and merge\ncompare = t6.merge(round(summary,3))\ncompare.head()\n\n\n\n\n\n\n\n\nt6_outcome\nconfig1_mean\nconfig1_sd\nconfig2_mean\nconfig2_sd\nconfig3_mean\nconfig3_sd\nbenchmark_mean\nbenchmark_sd\nmodel_outcome\nmodel_t6_c1_mean\nmodel_t6_c1_sd\nmodel_t6_c2_mean\nmodel_t6_c2_sd\nmodel_t6_c3_mean\nmodel_t6_c3_sd\nmodel_t6_c4_mean\nmodel_t6_c4_sd\n\n\n\n\n0\nDoctor utilisation\n0.268\n0.003\n0.372\n0.004\n0.354\n0.002\n1.142\n0.006\ndoc occ\n0.269\n0.002\n0.372\n0.004\n0.354\n0.002\n1.144\n0.006\n\n\n1\nNCD Nurse utilisation\n0.865\n0.011\n0.469\n0.005\n0.468\n0.005\n1.232\n0.019\nNCD occ\n0.866\n0.010\n0.469\n0.006\n0.468\n0.005\n1.231\n0.019\n\n\n2\nStaff nurse utilisation\n0.323\n0.008\n0.243\n0.006\n0.160\n0.001\n0.322\n0.008\nstaff nurse occ\n0.323\n0.008\n0.243\n0.006\n0.161\n0.001\n0.324\n0.008\n\n\n3\nPharmacist utilisation\n0.643\n0.004\n0.288\n0.003\n0.289\n0.003\n0.855\n0.005\npharm occ\n0.643\n0.004\n0.289\n0.003\n0.288\n0.002\n0.855\n0.004\n\n\n4\nLab utilisation\n0.559\n0.008\n0.254\n0.004\n0.239\n0.004\n0.736\n0.011\nlab occ\n0.559\n0.008\n0.254\n0.005\n0.239\n0.004\n0.734\n0.012\n\n\n\n\n\n\n\n\ncompare_col = [\n    ('config1_mean', 'model_t6_c1_mean'),\n    ('config1_sd', 'model_t6_c1_sd'),\n    ('config2_mean', 'model_t6_c2_mean'),\n    ('config2_sd', 'model_t6_c2_sd'),\n    ('config3_mean', 'model_t6_c3_mean'),\n    ('config3_sd', 'model_t6_c3_sd'),\n    ('benchmark_mean', 'model_t6_c4_mean'),\n    ('benchmark_sd', 'model_t6_c4_sd'),]\n\nfor col in compare_col:\n    # Find difference between two columns\n    compare[f'change_{col[1]}'] = abs(compare[col[1]] - compare[col[0]])\n    # Find percent change between two columns\n    subset = compare[list(col)]\n    pct_change = subset.pct_change(axis=1).iloc[:, 1]*100\n    compare[f'pct_change_{col[1]}'] = pct_change\n\n# Display each of the results\nfor col in compare_col:\n    # Set outcome as index, and get the two results plus percent change\n    subset = compare.set_index('t6_outcome')[\n        list(col) + [f'change_{col[1]}', f'pct_change_{col[1]}']]\n    display(subset)\n\n\n\n\n\n\n\n\nconfig1_mean\nmodel_t6_c1_mean\nchange_model_t6_c1_mean\npct_change_model_t6_c1_mean\n\n\nt6_outcome\n\n\n\n\n\n\n\n\nDoctor utilisation\n0.268\n0.269\n0.001\n0.373134\n\n\nNCD Nurse utilisation\n0.865\n0.866\n0.001\n0.115607\n\n\nStaff nurse utilisation\n0.323\n0.323\n0.000\n0.000000\n\n\nPharmacist utilisation\n0.643\n0.643\n0.000\n0.000000\n\n\nLab utilisation\n0.559\n0.559\n0.000\n0.000000\n\n\nInpatient bed utilisation\n0.093\n0.094\n0.001\n1.075269\n\n\nLabour bed utilisation\n0.283\n0.283\n0.000\n0.000000\n\n\nMean length of OPD queue (number of patients)\n0.000\n0.001\n0.001\ninf\n\n\nOPD queue waiting time (minutes)\n0.009\n0.009\n0.000\n0.000000\n\n\nMean length of pharmacy queue (number of patients)\n0.090\n0.090\n0.000\n0.000000\n\n\nPharmacy queue waiting time (minutes)\n1.025\n1.025\n0.000\n0.000000\n\n\nMean length of Lab queue (number of patients)\n0.094\n0.095\n0.001\n1.063830\n\n\nLab queue waiting time (minutes)\n2.084\n2.077\n0.007\n-0.335893\n\n\nFraction of childbirth cases referred\n0.156\n0.154\n0.002\n-1.282051\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconfig1_sd\nmodel_t6_c1_sd\nchange_model_t6_c1_sd\npct_change_model_t6_c1_sd\n\n\nt6_outcome\n\n\n\n\n\n\n\n\nDoctor utilisation\n0.003\n0.002\n0.001\n-33.333333\n\n\nNCD Nurse utilisation\n0.011\n0.010\n0.001\n-9.090909\n\n\nStaff nurse utilisation\n0.008\n0.008\n0.000\n0.000000\n\n\nPharmacist utilisation\n0.004\n0.004\n0.000\n0.000000\n\n\nLab utilisation\n0.008\n0.008\n0.000\n0.000000\n\n\nInpatient bed utilisation\n0.004\n0.004\n0.000\n0.000000\n\n\nLabour bed utilisation\n0.010\n0.012\n0.002\n20.000000\n\n\nMean length of OPD queue (number of patients)\n0.000\n0.000\n0.000\nNaN\n\n\nOPD queue waiting time (minutes)\n0.004\n0.003\n0.001\n-25.000000\n\n\nMean length of pharmacy queue (number of patients)\n0.002\n0.002\n0.000\n0.000000\n\n\nPharmacy queue waiting time (minutes)\n0.021\n0.022\n0.001\n4.761905\n\n\nMean length of Lab queue (number of patients)\n0.003\n0.003\n0.000\n0.000000\n\n\nLab queue waiting time (minutes)\n0.054\n0.056\n0.002\n3.703704\n\n\nFraction of childbirth cases referred\n0.019\n0.016\n0.003\n-15.789474\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconfig2_mean\nmodel_t6_c2_mean\nchange_model_t6_c2_mean\npct_change_model_t6_c2_mean\n\n\nt6_outcome\n\n\n\n\n\n\n\n\nDoctor utilisation\n0.372\n0.372\n0.000\n0.000000\n\n\nNCD Nurse utilisation\n0.469\n0.469\n0.000\n0.000000\n\n\nStaff nurse utilisation\n0.243\n0.243\n0.000\n0.000000\n\n\nPharmacist utilisation\n0.288\n0.289\n0.001\n0.347222\n\n\nLab utilisation\n0.254\n0.254\n0.000\n0.000000\n\n\nInpatient bed utilisation\n0.055\n0.056\n0.001\n1.818182\n\n\nLabour bed utilisation\n0.153\n0.152\n0.001\n-0.653595\n\n\nMean length of OPD queue (number of patients)\n0.007\n0.007\n0.000\n0.000000\n\n\nOPD queue waiting time (minutes)\n0.171\n0.183\n0.012\n7.017544\n\n\nMean length of pharmacy queue (number of patients)\n0.010\n0.010\n0.000\n0.000000\n\n\nPharmacy queue waiting time (minutes)\n0.244\n0.245\n0.001\n0.409836\n\n\nMean length of Lab queue (number of patients)\n0.012\n0.012\n0.000\n0.000000\n\n\nLab queue waiting time (minutes)\n0.606\n0.605\n0.001\n-0.165017\n\n\nFraction of childbirth cases referred\n0.088\n0.086\n0.002\n-2.272727\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconfig2_sd\nmodel_t6_c2_sd\nchange_model_t6_c2_sd\npct_change_model_t6_c2_sd\n\n\nt6_outcome\n\n\n\n\n\n\n\n\nDoctor utilisation\n0.004\n0.004\n0.000\n0.000000\n\n\nNCD Nurse utilisation\n0.005\n0.006\n0.001\n20.000000\n\n\nStaff nurse utilisation\n0.006\n0.006\n0.000\n0.000000\n\n\nPharmacist utilisation\n0.003\n0.003\n0.000\n0.000000\n\n\nLab utilisation\n0.004\n0.005\n0.001\n25.000000\n\n\nInpatient bed utilisation\n0.003\n0.004\n0.001\n33.333333\n\n\nLabour bed utilisation\n0.009\n0.011\n0.002\n22.222222\n\n\nMean length of OPD queue (number of patients)\n0.001\n0.001\n0.000\n0.000000\n\n\nOPD queue waiting time (minutes)\n0.032\n0.029\n0.003\n-9.375000\n\n\nMean length of pharmacy queue (number of patients)\n0.001\n0.000\n0.001\n-100.000000\n\n\nPharmacy queue waiting time (minutes)\n0.008\n0.009\n0.001\n12.500000\n\n\nMean length of Lab queue (number of patients)\n0.001\n0.001\n0.000\n0.000000\n\n\nLab queue waiting time (minutes)\n0.023\n0.023\n0.000\n0.000000\n\n\nFraction of childbirth cases referred\n0.022\n0.018\n0.004\n-18.181818\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconfig3_mean\nmodel_t6_c3_mean\nchange_model_t6_c3_mean\npct_change_model_t6_c3_mean\n\n\nt6_outcome\n\n\n\n\n\n\n\n\nDoctor utilisation\n0.354\n0.354\n0.000\n0.000000\n\n\nNCD Nurse utilisation\n0.468\n0.468\n0.000\n0.000000\n\n\nStaff nurse utilisation\n0.160\n0.161\n0.001\n0.625000\n\n\nPharmacist utilisation\n0.289\n0.288\n0.001\n-0.346021\n\n\nLab utilisation\n0.239\n0.239\n0.000\n0.000000\n\n\nInpatient bed utilisation\n0.011\n0.012\n0.001\n9.090909\n\n\nLabour bed utilisation\nNaN\nNaN\nNaN\nNaN\n\n\nMean length of OPD queue (number of patients)\n0.001\n0.001\n0.000\n0.000000\n\n\nOPD queue waiting time (minutes)\n0.034\n0.035\n0.001\n2.941176\n\n\nMean length of pharmacy queue (number of patients)\n0.009\n0.009\n0.000\n0.000000\n\n\nPharmacy queue waiting time (minutes)\n0.232\n0.231\n0.001\n-0.431034\n\n\nMean length of Lab queue (number of patients)\n0.011\n0.011\n0.000\n0.000000\n\n\nLab queue waiting time (minutes)\n0.571\n0.570\n0.001\n-0.175131\n\n\nFraction of childbirth cases referred\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconfig3_sd\nmodel_t6_c3_sd\nchange_model_t6_c3_sd\npct_change_model_t6_c3_sd\n\n\nt6_outcome\n\n\n\n\n\n\n\n\nDoctor utilisation\n0.002\n0.002\n0.000\n0.000000\n\n\nNCD Nurse utilisation\n0.005\n0.005\n0.000\n0.000000\n\n\nStaff nurse utilisation\n0.001\n0.001\n0.000\n0.000000\n\n\nPharmacist utilisation\n0.003\n0.002\n0.001\n-33.333333\n\n\nLab utilisation\n0.004\n0.004\n0.000\n0.000000\n\n\nInpatient bed utilisation\n0.001\n0.001\n0.000\n0.000000\n\n\nLabour bed utilisation\nNaN\nNaN\nNaN\nNaN\n\n\nMean length of OPD queue (number of patients)\n0.000\n0.000\n0.000\nNaN\n\n\nOPD queue waiting time (minutes)\n0.001\n0.001\n0.000\n0.000000\n\n\nMean length of pharmacy queue (number of patients)\n0.000\n0.000\n0.000\nNaN\n\n\nPharmacy queue waiting time (minutes)\n0.006\n0.006\n0.000\n0.000000\n\n\nMean length of Lab queue (number of patients)\n0.000\n0.000\n0.000\nNaN\n\n\nLab queue waiting time (minutes)\n0.020\n0.019\n0.001\n-5.000000\n\n\nFraction of childbirth cases referred\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbenchmark_mean\nmodel_t6_c4_mean\nchange_model_t6_c4_mean\npct_change_model_t6_c4_mean\n\n\nt6_outcome\n\n\n\n\n\n\n\n\nDoctor utilisation\n1.142\n1.144\n0.002\n0.175131\n\n\nNCD Nurse utilisation\n1.232\n1.231\n0.001\n-0.081169\n\n\nStaff nurse utilisation\n0.322\n0.324\n0.002\n0.621118\n\n\nPharmacist utilisation\n0.855\n0.855\n0.000\n0.000000\n\n\nLab utilisation\n0.736\n0.734\n0.002\n-0.271739\n\n\nInpatient bed utilisation\n0.093\n0.094\n0.001\n1.075269\n\n\nLabour bed utilisation\n0.281\n0.281\n0.000\n0.000000\n\n\nMean length of OPD queue (number of patients)\n0.817\n0.817\n0.000\n0.000000\n\n\nOPD queue waiting time (minutes)\n6.789\n6.969\n0.180\n2.651348\n\n\nMean length of pharmacy queue (number of patients)\n0.150\n0.150\n0.000\n0.000000\n\n\nPharmacy queue waiting time (minutes)\n1.282\n1.284\n0.002\n0.156006\n\n\nMean length of Lab queue (number of patients)\n0.188\n0.189\n0.001\n0.531915\n\n\nLab queue waiting time (minutes)\n3.135\n3.153\n0.018\n0.574163\n\n\nFraction of childbirth cases referred\n0.157\n0.161\n0.004\n2.547771\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbenchmark_sd\nmodel_t6_c4_sd\nchange_model_t6_c4_sd\npct_change_model_t6_c4_sd\n\n\nt6_outcome\n\n\n\n\n\n\n\n\nDoctor utilisation\n0.006\n0.006\n0.000\n0.000000\n\n\nNCD Nurse utilisation\n0.019\n0.019\n0.000\n0.000000\n\n\nStaff nurse utilisation\n0.008\n0.008\n0.000\n0.000000\n\n\nPharmacist utilisation\n0.005\n0.004\n0.001\n-20.000000\n\n\nLab utilisation\n0.011\n0.012\n0.001\n9.090909\n\n\nInpatient bed utilisation\n0.004\n0.004\n0.000\n0.000000\n\n\nLabour bed utilisation\n0.012\n0.013\n0.001\n8.333333\n\n\nMean length of OPD queue (number of patients)\n0.027\n0.032\n0.005\n18.518519\n\n\nOPD queue waiting time (minutes)\n0.268\n0.252\n0.016\n-5.970149\n\n\nMean length of pharmacy queue (number of patients)\n0.002\n0.003\n0.001\n50.000000\n\n\nPharmacy queue waiting time (minutes)\n0.018\n0.020\n0.002\n11.111111\n\n\nMean length of Lab queue (number of patients)\n0.001\n0.006\n0.005\n500.000000\n\n\nLab queue waiting time (minutes)\n0.005\n0.073\n0.068\n1360.000000\n\n\nFraction of childbirth cases referred\n0.180\n0.019\n0.161\n-89.444444"
  },
  {
    "objectID": "reproduction/reproduce_tab6.html#format-model-results-like-table-6-and-save",
    "href": "reproduction/reproduce_tab6.html#format-model-results-like-table-6-and-save",
    "title": "Reproducing Table 6",
    "section": "Format model results like table 6, and save",
    "text": "Format model results like table 6, and save\n\ncompare_col = [\n    ['Configuration 1', 'model_t6_c1_mean', 'model_t6_c1_sd'],\n    ['Configuration 2', 'model_t6_c2_mean', 'model_t6_c2_sd'],\n    ['Configuration 3', 'model_t6_c3_mean', 'model_t6_c3_sd'],\n    ['Benchmark Case', 'model_t6_c4_mean', 'model_t6_c4_sd']]\n\n# Combine each pair of columns into string as in Table 6\nfor col in compare_col:\n    compare[col[0]] = (\n        round(compare[col[1]], 3).astype(str) + ' (' +\n        round(compare[col[2]], 3).astype(str) + ')')\n\n# Set outcome name as index, and select those columns\nformatted_model_res = (compare\n                       .set_index('t6_outcome')\n                       .rename_axis('Simulation Outcome')[\n                           [item[0] for item in compare_col]])\nformatted_model_res\n\n\n\n\n\n\n\n\nConfiguration 1\nConfiguration 2\nConfiguration 3\nBenchmark Case\n\n\nSimulation Outcome\n\n\n\n\n\n\n\n\nDoctor utilisation\n0.269 (0.002)\n0.372 (0.004)\n0.354 (0.002)\n1.144 (0.006)\n\n\nNCD Nurse utilisation\n0.866 (0.01)\n0.469 (0.006)\n0.468 (0.005)\n1.231 (0.019)\n\n\nStaff nurse utilisation\n0.323 (0.008)\n0.243 (0.006)\n0.161 (0.001)\n0.324 (0.008)\n\n\nPharmacist utilisation\n0.643 (0.004)\n0.289 (0.003)\n0.288 (0.002)\n0.855 (0.004)\n\n\nLab utilisation\n0.559 (0.008)\n0.254 (0.005)\n0.239 (0.004)\n0.734 (0.012)\n\n\nInpatient bed utilisation\n0.094 (0.004)\n0.056 (0.004)\n0.012 (0.001)\n0.094 (0.004)\n\n\nLabour bed utilisation\n0.283 (0.012)\n0.152 (0.011)\nnan (nan)\n0.281 (0.013)\n\n\nMean length of OPD queue (number of patients)\n0.001 (0.0)\n0.007 (0.001)\n0.001 (0.0)\n0.817 (0.032)\n\n\nOPD queue waiting time (minutes)\n0.009 (0.003)\n0.183 (0.029)\n0.035 (0.001)\n6.969 (0.252)\n\n\nMean length of pharmacy queue (number of patients)\n0.09 (0.002)\n0.01 (0.0)\n0.009 (0.0)\n0.15 (0.003)\n\n\nPharmacy queue waiting time (minutes)\n1.025 (0.022)\n0.245 (0.009)\n0.231 (0.006)\n1.284 (0.02)\n\n\nMean length of Lab queue (number of patients)\n0.095 (0.003)\n0.012 (0.001)\n0.011 (0.0)\n0.189 (0.006)\n\n\nLab queue waiting time (minutes)\n2.077 (0.056)\n0.605 (0.023)\n0.57 (0.019)\n3.153 (0.073)\n\n\nFraction of childbirth cases referred\n0.154 (0.016)\n0.086 (0.018)\nnan (nan)\n0.161 (0.019)\n\n\n\n\n\n\n\n\nformatted_model_res.to_csv(final_results)\n\n\n# Find run time in seconds\n# end = time.time()\n# runtime = round(end-start)\n\n# Display converted to minutes and seconds\n# print(f'Notebook run time: {runtime//60}m {runtime%60}s')"
  },
  {
    "objectID": "reproduction/reproduce_fig3.html",
    "href": "reproduction/reproduce_fig3.html",
    "title": "Reproducing Figure 3A-D",
    "section": "",
    "text": "Figure 2 presents results from sensitivity analysis of configuration 1.\nNote: These are created from 10 replications currently for simplicity. At 10 replications, we would expect mean values to vary only slightly from further replication numbers. Hence, if felt similar at 10, have marked as succesfully reproduced without also testing at 100 replications."
  },
  {
    "objectID": "reproduction/reproduce_fig3.html#parameters",
    "href": "reproduction/reproduce_fig3.html#parameters",
    "title": "Reproducing Figure 3A-D",
    "section": "Parameters",
    "text": "Parameters\nIn these figures, we vary:\n\nNumber of inpatient/childbirth/ANC cases per day:\n\n1 = IAT 1440 (e.g. like IPD cases for config1)\n2 = IAT 720 (as 2880 is 0.5 per day and 1440 is 1 per day)\n\nAverage service time for outpatients:\n\n0.87 (0.21) (same as config1)\n2.5 (0.5) (as in figure 2)"
  },
  {
    "objectID": "reproduction/reproduce_fig3.html#set-up",
    "href": "reproduction/reproduce_fig3.html#set-up",
    "title": "Reproducing Figure 3A-D",
    "section": "Set up",
    "text": "Set up\n\n# To run model\nimport PHC\n\n# To import results and produce figures\nimport xlrd\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# To speed up run time\nfrom multiprocessing import Pool\n\n'''\n# Additional package to record runtime of this notebook\nimport time\nstart = time.time()\n'''\n\n'\\n# Additional package to record runtime of this notebook\\nimport time\\nstart = time.time()\\n'\n\n\n\n# Paths to save image files to\noutput_folder = 'outputs'\nfig3a_path = os.path.join(output_folder, 'fig3a.png')\nfig3b_path = os.path.join(output_folder, 'fig3b.png')\nfig3c_path = os.path.join(output_folder, 'fig3c.png')\nfig3d_path = os.path.join(output_folder, 'fig3d.png')"
  },
  {
    "objectID": "reproduction/reproduce_fig3.html#run-model",
    "href": "reproduction/reproduce_fig3.html#run-model",
    "title": "Reproducing Figure 3A-D",
    "section": "Run model",
    "text": "Run model\n\n# TODO: Run with 100 replications\n\n# Varying number of inpatient, childbirth and ANC cases\narr_dict = [\n    {\n        'IPD_iat': 1440,\n        'delivery_iat': 1440,\n        'ANC_iat': 1440,\n        'rep_file': 'arr111'\n    },\n    {\n        'IPD_iat': 720,\n        'delivery_iat': 1440,\n        'ANC_iat': 1440,\n        'rep_file': 'arr211',\n    },\n    {\n        'IPD_iat': 720,\n        'delivery_iat': 720,\n        'ANC_iat': 720,\n        'rep_file': 'arr222',\n    }\n]\n\n# Varying service time\nserv_dict = [\n    {\n        'mean': 0.87,\n        'sd': 0.21,\n        'consult_boundary_1': 0.5,  # From PHC.py\n        'consult_boundary_2': 0.3,  # From PHC.py\n        'rep_file': 'serv087'\n    },\n    {\n        'mean': 2.5,\n        'sd': 0.5,\n        'consult_boundary_1': 1,  # From Figure 2 (which was a guess)\n        'consult_boundary_2': 1,  # From Figure 2 (which was a guess)\n        'rep_file': 'serv25'\n    }\n]\n\nCreate each combination for the reproduction\n\ndict_list = []\nfor arr in arr_dict:\n    for serv in serv_dict:\n        # Combine the dictionaries\n        comb = {**arr, **serv}\n        # Replace the file name\n        comb['rep_file'] = f'''f3_{arr['rep_file']}_{serv['rep_file']}.xls'''\n        # Save to list\n        dict_list.append(comb)\n\nlen(dict_list)\n\n6\n\n\n\n# Append 's_' to all items\nfor i, d in enumerate(dict_list):\n    dict_list[i] = {f's_{k}': v for k, v in d.items()}\n\n# Preview example\ndict_list[0]\n\n{'s_IPD_iat': 1440,\n 's_delivery_iat': 1440,\n 's_ANC_iat': 1440,\n 's_rep_file': 'f3_arr111_serv087.xls',\n 's_mean': 0.87,\n 's_sd': 0.21,\n 's_consult_boundary_1': 0.5,\n 's_consult_boundary_2': 0.3}\n\n\nRun the model (with parallel processing to reduce run time)\n\n'''\n# Wrapper function to allow input of dictionary with pool\ndef wrapper(d):\n    return PHC.main(**d)\n\n# Create a process pool that uses all CPUs\nwith Pool() as pool:\n    # Run PHC.main() using each of inputs from config\n    pool.map(wrapper, dict_list)\n'''\n\n'\\n# Wrapper function to allow input of dictionary with pool\\ndef wrapper(d):\\n    return PHC.main(**d)\\n\\n# Create a process pool that uses all CPUs\\nwith Pool() as pool:\\n    # Run PHC.main() using each of inputs from config\\n    pool.map(wrapper, dict_list)\\n'"
  },
  {
    "objectID": "reproduction/reproduce_fig3.html#process-results",
    "href": "reproduction/reproduce_fig3.html#process-results",
    "title": "Reproducing Figure 3A-D",
    "section": "Process results",
    "text": "Process results\n\ndef process_results(files):\n    '''\n    Imports files in provided list and produces a single dataframe with mean\n    results from across the replications\n\n    Parameters:\n    ----------\n    files : list\n        List of file names (exc. file type) containing replication results\n\n    Returns:\n    --------\n    summary : dataframe\n        Dataframe with mean results for each model variant in file list\n    '''\n    # Empty list to store results\n    result_list = []\n\n    for f in files:\n        # Import .xls and convert to pandas dataframe\n        book = xlrd.open_workbook(os.path.join(output_folder, f'{f}.xls'))\n        result = pd.read_excel(book, header=None, index_col=0)\n\n        # Find mean from the replication\n        # Save as dataframe, dropping the duplicate rows (NCD occ twice)\n        res = pd.DataFrame({f: result.mean(axis=1)}).drop_duplicates()\n\n        # Remove index name\n        res.index.name = None\n\n        # Save to list\n        result_list.append(res)\n\n    # Combine into single dataframe\n    summary = pd.concat(result_list, axis=1)\n\n    return summary"
  },
  {
    "objectID": "reproduction/reproduce_fig3.html#create-figure-3a",
    "href": "reproduction/reproduce_fig3.html#create-figure-3a",
    "title": "Reproducing Figure 3A-D",
    "section": "Create Figure 3A",
    "text": "Create Figure 3A\n\n# Import and process results\ndata_full = process_results([\n    'f3_arr111_serv087', 'f3_arr211_serv087', 'f3_arr222_serv087',\n    'f3_arr111_serv25', 'f3_arr211_serv25', 'f3_arr222_serv25'])\n\n# Filter to doctor utilisation\na3 = data_full.loc['doc occ']\na3\n\nf3_arr111_serv087    0.269199\nf3_arr211_serv087    0.271072\nf3_arr222_serv087    0.289770\nf3_arr111_serv25     0.513668\nf3_arr211_serv25     0.517088\nf3_arr222_serv25     0.537383\nName: doc occ, dtype: float64\n\n\n\n# Reshape data so in appropriate format for plotting grouped bar chart\nnames = ['0.87 (0.21)', '2.5 (0.5)']\ns111 = [a3['f3_arr111_serv087'], a3['f3_arr111_serv25']]\ns211 = [a3['f3_arr211_serv087'], a3['f3_arr211_serv25']]\ns222 = [a3['f3_arr222_serv087'], a3['f3_arr222_serv25']]\n\ndata_3a = pd.DataFrame(\n    {'(1/1/1)': s111, '(2/1/1)': s211, '(2/2/2)': s222}, index=names)\ndata_3a\n\n\n\n\n\n\n\n\n(1/1/1)\n(2/1/1)\n(2/2/2)\n\n\n\n\n0.87 (0.21)\n0.269199\n0.271072\n0.289770\n\n\n2.5 (0.5)\n0.513668\n0.517088\n0.537383\n\n\n\n\n\n\n\n\n# Plot data\nax = data_3a.plot.bar(edgecolor='black', color='white', width=0.7)\n\n# Add patterns\nbars = ax.patches\npattern = np.repeat(['++', '\\\\\\\\\\\\\\\\', '//////'], 2)\nfor bar, hatch in zip(bars, pattern):\n    bar.set_hatch(hatch)\nax.legend(title='Inpatient/Childbirth/ANC cases per day')\n\n# Adjust figure\nplt.xlabel('Consultation time (minutes): mean (SD)')\nplt.ylabel('''Doctor's utilisation''')\nplt.xticks(rotation=0)\nax.grid(axis='y')\nplt.ylim(0, 1)\nax.set_axisbelow(True)\nplt.savefig(fig3a_path, bbox_inches='tight')\nplt.show()"
  },
  {
    "objectID": "reproduction/reproduce_fig3.html#run-time",
    "href": "reproduction/reproduce_fig3.html#run-time",
    "title": "Reproducing Figure 3A-D",
    "section": "Run time",
    "text": "Run time\n\n'''\n# Find run time in seconds\nend = time.time()\nruntime = round(end-start)\n\n# Display converted to minutes and seconds\nprint(f'Notebook run time: {runtime//60}m {runtime%60}s')\n'''\n\n\"\\n# Find run time in seconds\\nend = time.time()\\nruntime = round(end-start)\\n\\n# Display converted to minutes and seconds\\nprint(f'Notebook run time: {runtime//60}m {runtime%60}s')\\n\""
  }
]