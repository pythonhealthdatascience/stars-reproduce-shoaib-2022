---
title: "Day 4"
author: "Amy Heather"
date: "2024-06-25"
categories: [reproduce]
bibliography: ../../../quarto_site/references.bib
---

## 6.55-6.57: Run 100 replications for Table 6

Start running with 100 replications. Taking too long (ran through 259 replications in 110 minutes), so only got through 2 full configurations before needing to shut it down to go to work.

## 9.26-9.50, 10.50-10.51: Used parallel processing when running the replications

Set up parallel processing in `reproduce_tab6.ipynb` to run the 4 sets of 100 replications. It took 61 minutes to run (excluded from timing). Once complete, I looked over the table and was satisified that the mean and SD values were close enough to the original, and considered it now completely successfully reproduced (at timestamp: 10.51). I disregarded some high percent change that were simply due to comparison of numbers very close to zero, and the difference was actually very small.

Emailed to Tom and Alison to share second opinion.

Timing for when Table 6 is completed (i.e. as of 10.51):

```{python}
import sys
sys.path.append('../')
from timings import calculate_times

# Minutes used prior to today
used_to_date = 829

# Times from today
times = [
    ('6.55', '6.57'),
    ('9.26', '9.50'),
    ('10.50', '10.51')]

calculate_times(used_to_date, times)
```

## 11.04-11.17: Saved output from processed replications, and confirmation from Tom and Alison

Edited notebook so model is not re-run each time (due to long run time), and then saved the processed results to a csv file.

Both Tom and Alison responded to confirm they were happy this was reproduced.

Re-ran % change calculations with rounded values. As before, observe that we are sometimes comparing very small numbers - so e.g. mean of 0.011 v.s. 0.012 comes out as 9% change. It also sometimes finds large differences for small SD values (e.g. 1360% change), when actually, I'm not too concerned by the difference in the grand scheme of things.

## 11.30-11.50: Create Figure 2B

Imported and processed data from the arrival number replications, and produced Figure 2B. Happy that this is succesfully reproduced at timepoint 11.50. In order to declare this reproduced, I feel I do not require to run the same number of replications (100), as understand this would have no meaningful impact on result being plot (mean), and am happy with consistency to original at 10 replications.

```{python}
# Minutes used prior to today
used_to_date = 829

# Times from today
times = [
    ('6.55', '6.57'),
    ('9.26', '9.50'),
    ('10.50', '10.51'),
    ('11.04', '11.17'),
    ('11.30', '11.50')]

calculate_times(used_to_date, times)
```

## 11.51-12.08, 12.13-12.17: Create Figure 2C

Using `OPD Q wt` (which matched up to OPD queue waiting time for Table 6), results look rather different. They only go up to 0.01, whilst in Figure 2C, results go from under 1 up to just under 7. That is closer to the waiting time in the benchmark model, implying these results are obtained with those doctor numbers.

![Incorrect reproduction of Fig2c](fig2c_incorrect.png)

When run with the `serv5` appointment times, the results match up with the paper. Feel this has been succesfully reproduced at time 12.17.

![Successful reproduction of Fig2c](fig2c_fixed.png)

```{python}
# Minutes used prior to today
used_to_date = 829

# Times from today
times = [
    ('6.55', '6.57'),
    ('9.26', '9.50'),
    ('10.50', '10.51'),
    ('11.04', '11.17'),
    ('11.30', '11.50'),
    ('11.51', '12.08'),
    ('12.13', '12.17')]

calculate_times(used_to_date, times)
```

## Timings

```{python}
# Times from today
times = [
    ('6.55', '6.57'),
    ('9.26', '9.50'),
    ('10.50', '10.51'),
    ('11.04', '11.17'),
    ('11.30', '11.50'),
    ('11.51', '12.08'),
    ('12.13', '12.17')]

calculate_times(used_to_date, times)
```